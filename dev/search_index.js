var documenterSearchIndex = {"docs":
[{"location":"api/","page":"API","title":"API","text":"<img src=\"https://raw.githubusercontent.com/itsdfish/TrueAndErrorModels.jl/gh-pages/dev/assets/logo_readme.png\" alt=\"drawing\" width=\"900\"/>","category":"page"},{"location":"api/","page":"API","title":"API","text":"Modules = [TrueAndErrorModels]\nOrder   = [:type, :function]\nPrivate = false","category":"page"},{"location":"api/#TrueAndErrorModels.TrueErrorModel","page":"API","title":"TrueAndErrorModels.TrueErrorModel","text":"TrueErrorModel{T <: Real} <: AbstractTrueErrorModel\n\nA model object for a True and Error Model of Allias Paradox. Two choice sets are presented twice during the same session,  meaning 4 choices are made in total. Subscript r represents risky, subscript s represents safe, and subscripts 1 and 2 represent choice set. For example, pᵣᵣ represents the probability of truely prefering the risky option in both choice sets and ϵₛ₁ represents the error probability of choosing safe given a true preference for risky in first choice set. \n\nFields\n\np::AbstractVector{T}: a vector of true preference state probabilities with elements p = [pᵣᵣ, pᵣₛ, pₛᵣ, pₛₛ], such that sum(p) = 1. \np::AbstractVector{T}: a vector of error probabilities with elements ϵ = [ϵₛ₁, ϵₛ₂, ϵᵣ₁, ϵᵣ₂].\n\nConstructors\n\nTrueErrorModel(p, ϵ)\n\nTrueErrorModel(; p, ϵ)\n\nExample\n\nusing TrueAndErrorModels\n\ndist = TrueErrorModel(; p = [0.60, .30, .05, .05], ϵ = fill(.10, 4))\ndata = rand(dist, 200)\nlogpdf(dist, data)\n\nDocumentation\n\nFull documentation can be found at https://itsdfish.github.io/TrueAndErrorModels.jl/dev/\n\nReferences\n\nBirnbaum, M. H., & Quispe-Torreblanca, E. G. (2018). TEMAP2. R: True and error model analysis program in R. Judgment and Decision Making, 13(5), 428-440.\n\nLee, M. D. (2018). Bayesian methods for analyzing true-and-error models. Judgment and Decision Making, 13(6), 622-635.\n\n\n\n\n\n","category":"type"},{"location":"api/#Base.rand-Tuple{TrueErrorModel, Int64}","page":"API","title":"Base.rand","text":"rand(dist::TrueErrorModel, n_trials::Int)\n\nGenerate \n\ndist::TrueErrorModel{T}: a distribution object for a True and Error Model for two choices sets, each containing\n\na risky option R and a safe option S.\n\nn_trials: the number of simulated trials \n\nOutput\n\ndata::Vector{<:Int}: vector of joint response frequencies with the following elements:\n\nRR,RR\nRR,RS\nRR,SR\nRR,SS\nRS,RR\nRS,RS\nRS,SR\nRS,SS\nSR,RR\nSR,RS\nSR,SR\nSR,SS\nSS,RR\nSS,RS\nSS,SR\nSS,SS\n\nwhere S corresponds to choosing the safe option, R corresponds to choosing the risky option, each pair (XX) is the joint choice for choice sets 1 and two, respectively for a given replication. The first pair corresponds to  the first replication, and the second pair corresponds to the second replication. For example, SR,RS indicates the selection  of the safe option for choice set 1 followed by the risky option for choice set 2 during the first replication, and the  reversal of choices for the second replication. \n\n\n\n\n\n","category":"method"},{"location":"api/#TrueAndErrorModels.compute_probs-Union{Tuple{TrueErrorModel{T}}, Tuple{T}} where T","page":"API","title":"TrueAndErrorModels.compute_probs","text":"compute_probs(dist::TrueErrorModel{T})\n\nComputes the joint probability for all 16 response categories\n\nArguments\n\ndist::TrueErrorModel{T}: a distribution object for a True and Error Model for two choices sets, each containing\n\na risky option R and a safe option S.\n\nOutput\n\nθ::Vector{T}: vector of joint response probabilities with the following elements:\n\nRR,RR\nRR,RS\nRR,SR\nRR,SS\nRS,RR\nRS,RS\nRS,SR\nRS,SS\nSR,RR\nSR,RS\nSR,SR\nSR,SS\nSS,RR\nSS,RS\nSS,SR\nSS,SS\n\nwhere S corresponds to choosing the safe option, R corresponds to choosing the risky option, each pair (XX) is the joint choice for choice sets 1 and two, respectively for a given replication. The first pair corresponds to  the first replication, and the second pair corresponds to the second replication. For example, SR,RS indicates the selection  of the safe option for choice set 1 followed by the risky option for choice set 2 during the first replication, and the  reversal of choices for the second replication. \n\n\n\n\n\n","category":"method"},{"location":"api/","page":"API","title":"API","text":"tet1_model\ntet2_model\ntet4_model\neut1_model\neut2_model\neut4_model","category":"page"},{"location":"api/#TrueAndErrorModels.tet1_model","page":"API","title":"TrueAndErrorModels.tet1_model","text":"tet1_model(data::Vector{<:Integer})\n\nA True and Error Theory model with one error parameter: ϵₛ₁ = ϵₛ₂ = ϵᵣ₁ = ϵᵣ₂\n\nArguments\n\ndata::Vector{<:Integer}: a vector of response frequencies in which elements corrspond to the following response patterns:\n\nRR,RR\nRR,RS\nRR,SR\nRR,SS\nRS,RR\nRS,RS\nRS,SR\nRS,SS\nSR,RR\nSR,RS\nSR,SR\nSR,SS\nSS,RR\nSS,RS\nSS,SR\nSS,SS\n\nwhere S corresponds to choosing the safe option, R corresponds to choosing the risky option, each pair (XX) is the joint choice for choice sets 1 and two, respectively for a given replication. The first pair corresponds to  the first replication, and the second pair corresponds to the second replication. For example, SR,RS indicates the selection  of the safe option for choice set 1 followed by the risky option for choice set 2 during the first replication, and the  reversal of choices for the second replication. \n\n\n\n\n\n","category":"function"},{"location":"api/#TrueAndErrorModels.tet2_model","page":"API","title":"TrueAndErrorModels.tet2_model","text":"tet2_model(data::Vector{<:Integer})\n\nA True and Error Theory model with two error parameters: ϵₛ₁ = ϵᵣ₁, ϵₛ₂ = ϵᵣ₂\n\nArguments\n\ndata::Vector{<:Integer}: a vector of response frequencies in which elements corrspond to the following response patterns:\n\nRR,RR\nRR,RS\nRR,SR\nRR,SS\nRS,RR\nRS,RS\nRS,SR\nRS,SS\nSR,RR\nSR,RS\nSR,SR\nSR,SS\nSS,RR\nSS,RS\nSS,SR\nSS,SS\n\nwhere S corresponds to choosing the safe option, R corresponds to choosing the risky option, each pair (XX) is the joint choice for choice sets 1 and two, respectively for a given replication. The first pair corresponds to  the first replication, and the second pair corresponds to the second replication. For example, SR,RS indicates the selection  of the safe option for choice set 1 followed by the risky option for choice set 2 during the first replication, and the  reversal of choices for the second replication. \n\n\n\n\n\n","category":"function"},{"location":"api/#TrueAndErrorModels.tet4_model","page":"API","title":"TrueAndErrorModels.tet4_model","text":"tet4_model(data::Vector{<:Integer})\n\nA True and Error Theory model with four error parameters: ϵₛ₁, ϵᵣ₁, ϵₛ₂, ϵᵣ₂\n\nArguments\n\ndata::Vector{<:Integer}::Vector{<:Integer}: a vector of response frequencies in which elements corrspond to the following response patterns:\n\nRR,RR\nRR,RS\nRR,SR\nRR,SS\nRS,RR\nRS,RS\nRS,SR\nRS,SS\nSR,RR\nSR,RS\nSR,SR\nSR,SS\nSS,RR\nSS,RS\nSS,SR\nSS,SS\n\nwhere S corresponds to choosing the safe option, R corresponds to choosing the risky option, each pair (XX) is the joint choice for choice sets 1 and two, respectively for a given replication. The first pair corresponds to  the first replication, and the second pair corresponds to the second replication. For example, SR,RS indicates the selection  of the safe option for choice set 1 followed by the risky option for choice set 2 during the first replication, and the  reversal of choices for the second replication. \n\n\n\n\n\n","category":"function"},{"location":"api/#TrueAndErrorModels.eut1_model","page":"API","title":"TrueAndErrorModels.eut1_model","text":"eut1_model(data::Vector{<:Integer})\n\nAn expected utility theory model with one error parameter: ϵₛ₁ = ϵₛ₂ = ϵᵣ₁ = ϵᵣ₂. The preference states of all  expected utility theory models are subject to the constraint that pᵣₛ = pₛᵣ = 0.\n\nArguments\n\ndata::Vector{<:Integer}: a vector of response frequencies in which elements corrspond to the following response patterns:\n\nRR,RR\nRR,RS\nRR,SR\nRR,SS\nRS,RR\nRS,RS\nRS,SR\nRS,SS\nSR,RR\nSR,RS\nSR,SR\nSR,SS\nSS,RR\nSS,RS\nSS,SR\nSS,SS\n\nwhere S corresponds to choosing the safe option, R corresponds to choosing the risky option, each pair (XX) is the joint choice for choice sets 1 and two, respectively for a given replication. The first pair corresponds to  the first replication, and the second pair corresponds to the second replication. For example, SR,RS indicates the selection  of the safe option for choice set 1 followed by the risky option for choice set 2 during the first replication, and the  reversal of choices for the second replication. \n\n\n\n\n\n","category":"function"},{"location":"api/#TrueAndErrorModels.eut2_model","page":"API","title":"TrueAndErrorModels.eut2_model","text":"eut2_model(data::Vector{<:Integer})\n\nAn expected utility theory model with two error parameters: ϵₛ₁ = ϵᵣ₁, ϵₛ₂ = ϵᵣ₂. The preference states of all  expected utility theory models are subject to the constraint that pᵣₛ = pₛᵣ = 0.\n\nArguments\n\ndata::Vector{<:Integer}: a vector of response frequencies in which elements corrspond to the following response patterns:\n\nRR,RR\nRR,RS\nRR,SR\nRR,SS\nRS,RR\nRS,RS\nRS,SR\nRS,SS\nSR,RR\nSR,RS\nSR,SR\nSR,SS\nSS,RR\nSS,RS\nSS,SR\nSS,SS\n\nwhere S corresponds to choosing the safe option, R corresponds to choosing the risky option, each pair (XX) is the joint choice for choice sets 1 and two, respectively for a given replication. The first pair corresponds to  the first replication, and the second pair corresponds to the second replication. For example, SR,RS indicates the selection  of the safe option for choice set 1 followed by the risky option for choice set 2 during the first replication, and the  reversal of choices for the second replication. \n\n\n\n\n\n","category":"function"},{"location":"api/#TrueAndErrorModels.eut4_model","page":"API","title":"TrueAndErrorModels.eut4_model","text":"eut4_model(data::Vector{<:Integer})\n\nAn expected utility theory model with four error parameters: ϵₛ₁, ϵᵣ₁, ϵₛ₂, ϵᵣ₂. The preference states of all  expected utility theory models are subject to the constraint that pᵣₛ = pₛᵣ = 0.\n\nArguments\n\ndata::Vector{<:Integer}: a vector of response frequencies in which elements corrspond to the following response patterns:\n\nRR,RR\nRR,RS\nRR,SR\nRR,SS\nRS,RR\nRS,RS\nRS,SR\nRS,SS\nSR,RR\nSR,RS\nSR,SR\nSR,SS\nSS,RR\nSS,RS\nSS,SR\nSS,SS\n\nwhere S corresponds to choosing the safe option, R corresponds to choosing the risky option, each pair (XX) is the joint choice for choice sets 1 and two, respectively for a given replication. The first pair corresponds to  the first replication, and the second pair corresponds to the second replication. For example, SR,RS indicates the selection  of the safe option for choice set 1 followed by the risky option for choice set 2 during the first replication, and the  reversal of choices for the second replication. \n\n\n\n\n\n","category":"function"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"<img src=\"https://raw.githubusercontent.com/itsdfish/TrueAndErrorModels.jl/gh-pages/dev/assets/logo_readme.png\" alt=\"drawing\" width=\"900\"/>","category":"page"},{"location":"parameter_estimation/#Bayesian-Parameter-Estimation","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The purpose of this tutorial is to demonstrate how to perform Bayesian parameter estimation of the True and Error model (TET; Birnbaum & Quispe-Torreblanca, 2018) using the Turing.jl package. ","category":"page"},{"location":"parameter_estimation/#Load-Packages","page":"Bayesian Parameter Estimation","title":"Load Packages","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The first step is to load the required packages. You will need to install each package in your local environment in order to run the code locally. We will also set a random number generator so that the results are reproducible.","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"using Turing\nusing TrueAndErrorModels\nusing Random\nusing StatsPlots\nRandom.seed!(25044)","category":"page"},{"location":"parameter_estimation/#Generate-Data","page":"Bayesian Parameter Estimation","title":"Generate Data","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"For a description of the decision making task, please see the description in the model overview. In the code block below, we will create a model object and generate 2 simulated responses from 100 simulated subjects for a total of 200 responses. For this model, we assume that the probability of a true preference state RR is relatively high, and the probability of other preference states decreases as they become more difference from RR:","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"p_mathrmR_1R_2 = 65\np_mathrmR_1S_2 = 15\np_mathrmS_1R_2 = 15\np_mathrmS_1S_2 = 05","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"In addition, our model assumes the error probabilities are constrained to be equal:","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"epsilon_mathrmS_1 = epsilon_mathrmS_S = epsilon_mathrmR_1 =epsilon_mathrmR_2 = 10","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"dist = TrueErrorModel(; p = [0.65, .15, .15, .05], ϵ = fill(.10, 4))\ndata = rand(dist, 200)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"16-element Vector{Int64}:\n 87\n 11\n 13\n  1\n 13\n 18\n  0\n  3\n 10\n  2\n 18\n  1\n  4\n  5\n  2\n 12","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"In the output above, we see the response vector has 16 elements, which correspond to response frequencies for the 16 response patterns:","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"(mathcalR_1mathcalR_2mathcalR_1mathcalR_2)(mathcalR_1mathcalR_2mathcalR_1mathcalS_2) dots (mathcalS_1mathcalS_2mathcalS_1mathcalS_2)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"where mathcalR and mathcalS correspond to risky and safe options, respectively, and the subscript indexes the choice set.  ","category":"page"},{"location":"parameter_estimation/#The-Turing-Model","page":"Bayesian Parameter Estimation","title":"The Turing Model","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The TET1 model is automatically loaded when Turing is loaded into your Julia session. The tet1_model function accepts a vector of response frequencies. The prior distributions are as follows:","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"mathbfp sim mathrmDirichlet(1111)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"epsilon sim mathrmUniform(0 5)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"where mathbfp is a vector of four preference state parameters, and epsilon is a scalar. In the TET1 model, we assume epsilon = epsilon_mathrmS_1 = epsilon_mathrmS_S = epsilon_mathrmR_1 =epsilon_mathrmR_2. ","category":"page"},{"location":"parameter_estimation/#Estimate-the-Parameters","page":"Bayesian Parameter Estimation","title":"Estimate the Parameters","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Now that the Turing model has been specified, we can perform Bayesian parameter estimation with the function sample. We will use the No U-Turn Sampler (NUTS) to sample from the posterior distribution. The inputs into the sample function below are summarized as follows:","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"model(data): the Turing model with data passed\nNUTS(1000, .65): a sampler object for the No U-Turn Sampler for 1000 warmup samples.\nMCMCThreads(): instructs Turing to run each chain on a separate thread\nn_iterations: the number of iterations performed after warmup\nn_chains: the number of chains","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"# Estimate parameters\nchains = sample(tet1_model(data), NUTS(1000, .65), MCMCThreads(), 1000, 4)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"For ease of intepretation, we will convert the numerical indices of preference vector mathbfp to more informative labeled indices. ","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"name_map = Dict(\n    \"p[1]\" => \"pᵣᵣ\",\n    \"p[2]\" => \"pᵣₛ\",\n    \"p[3]\" => \"pₛᵣ\",\n    \"p[4]\" => \"pₛₛ\",\n)\nchains = replacenames(chains, name_map)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The output below shows the mean, standard deviation, effective sample size, and rhat for each of the five parameters. The pannel below shows the quantiles of the marginal distributions. ","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Chains MCMC chain (1000×20×4 Array{Float64, 3}):\n\nIterations        = 1001:1:2000\nNumber of chains  = 4\nSamples per chain = 1000\nWall duration     = 2.11 seconds\nCompute duration  = 6.21 seconds\nparameters        = pᵣᵣ, pᵣₛ, pₛᵣ, pₛₛ, ϵ\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ess_per_sec \n      Symbol   Float64   Float64   Float64     Float64     Float64   Float64       Float64 \n\n         pᵣᵣ    0.6580    0.0373    0.0005   6647.4436   3364.7026    1.0008      231.3522\n         pᵣₛ    0.1378    0.0293    0.0004   6554.7555   3621.5757    1.0000      228.1264\n         pₛᵣ    0.1180    0.0271    0.0004   5902.0436   2996.5486    1.0013      205.4099\n         pₛₛ    0.0862    0.0230    0.0003   6936.9475   3246.1778    1.0003      241.4279\n           ϵ    0.1018    0.0122    0.0002   6510.9497   3234.6554    1.0008      226.6018\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n\n         pᵣᵣ    0.5858    0.6331    0.6580    0.6833    0.7300\n         pᵣₛ    0.0843    0.1172    0.1365    0.1574    0.1980\n         pₛᵣ    0.0694    0.0991    0.1164    0.1362    0.1742\n         pₛₛ    0.0448    0.0699    0.0847    0.1012    0.1362\n           ϵ    0.0797    0.0937    0.1015    0.1095    0.1266","category":"page"},{"location":"parameter_estimation/#Evaluation","page":"Bayesian Parameter Estimation","title":"Evaluation","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"It is important to verify that the chains converged. We see that the chains converged according to hatr leq 105, and the trace plots below show that the chains look like \"hairy caterpillars\", which indicates the chains did not get stuck. ","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"post_plot = plot(chains, grid = false)\nvline!(post_plot, [missing .65 missing .15 missing .15 missing .05 missing .10], color = :black, linestyle = :dash)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"(Image: )","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The data-generating parameters are represented as black vertical lines in the density plots. As expected, the posterior distributions are centered near the data-generating parameters. Given that the data-generating and estimated model are the same, we would expect the posterior distributions to be near the data-generating parameters. ","category":"page"},{"location":"parameter_estimation/#References","page":"Bayesian Parameter Estimation","title":"References","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Birnbaum, M. H., & Quispe-Torreblanca, E. G. (2018). TEMAP2. R: True and error model analysis program in R. Judgment and Decision Making, 13(5), 428-440.","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Lee, M. D. (2018). Bayesian methods for analyzing true-and-error models. Judgment and Decision Making, 13(6), 622-635.","category":"page"},{"location":"turing_models/","page":"Off-the-shelf Turing Models","title":"Off-the-shelf Turing Models","text":"<img src=\"https://raw.githubusercontent.com/itsdfish/TrueAndErrorModels.jl/gh-pages/dev/assets/logo_readme.png\" alt=\"drawing\" width=\"900\"/>","category":"page"},{"location":"turing_models/#Turing-Models","page":"Off-the-shelf Turing Models","title":"Turing Models","text":"","category":"section"},{"location":"turing_models/","page":"Off-the-shelf Turing Models","title":"Off-the-shelf Turing Models","text":"TrueAndErrorModels.jl ships with off-the-shelf Turing models as described in Birnbaum, & Quispe-Torreblanca, (2018). The models become available when Turing is loaded into your current Julia session along with TrueAndErrorModels. The models have the following naming convention: The prefixes tet and eut correspond to True and Error Theory and Expected Utility Theory, respectively. The number corresponds to the number of error parameters. More details can be found in API.md.","category":"page"},{"location":"turing_models/#True-and-Error-Theory-Models","page":"Off-the-shelf Turing Models","title":"True and Error Theory Models","text":"","category":"section"},{"location":"turing_models/","page":"Off-the-shelf Turing Models","title":"Off-the-shelf Turing Models","text":"tet1_model\ntet2_model\ntet4_model","category":"page"},{"location":"turing_models/#Expected-Utility-Theory-Models","page":"Off-the-shelf Turing Models","title":"Expected Utility Theory Models","text":"","category":"section"},{"location":"turing_models/","page":"Off-the-shelf Turing Models","title":"Off-the-shelf Turing Models","text":"eut1_model\neut2_model\neut4_model","category":"page"},{"location":"turing_models/#References","page":"Off-the-shelf Turing Models","title":"References","text":"","category":"section"},{"location":"turing_models/","page":"Off-the-shelf Turing Models","title":"Off-the-shelf Turing Models","text":"Birnbaum, M. H., & Quispe-Torreblanca, E. G. (2018). TEMAP2. R: True and error model analysis program in R. Judgment and Decision Making, 13(5), 428-440.","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"<img src=\"https://raw.githubusercontent.com/itsdfish/TrueAndErrorModels.jl/gh-pages/dev/assets/logo_readme.png\" alt=\"drawing\" width=\"900\"/>","category":"page"},{"location":"bayes_factor/#Bayesian-Model-Comparison","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"","category":"section"},{"location":"bayes_factor/#Overview","page":"Bayesian Model Comparison","title":"Overview","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"In this tutorial, we will compare two True and Error model variants using the Bayes factor. One model variant imposes no restrictions on the error probability parameters, whereas the other model constrains the error probabilities to be equal. Computing the Bayes factor is challenging because it requires integrating over a potentially high dimensional parameter space. To compute Bayes factors, we will use a robust method called non-reversible parallel tempering (Bouchard-Côté et al., 2022) using the Julia package Pigeons.jl. ","category":"page"},{"location":"bayes_factor/#Bayes-Factor","page":"Bayesian Model Comparison","title":"Bayes Factor","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Before proceeding to the code, we provide a brief overview of the Bayes factor. Readers who are familiar with Bayes factors can skip this section. In Bayesian model comparison, the Bayes factor allows one to compare the probability of the data under two different models while taking into account model flexibility stemming all sources, including the number of parameters, functional form, and prior distribution. Thus, it provides a way to balance model fit and model flexibility into a single index. One important fact to keep in mind is that Bayes factors can be sensitive to the choice prior distributions over parameters. Sensitivity to prior distributions over parameters might be desireable depending on one's goals and knowledge of the models under consideration. ","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The Bayes factor is the likelihood of the data mathbfY = lefty_1y_2 dots y_nright under model mathcalM_i vs. model mathcalM_j. The relationship between the Bayes Factor and the posterior of odds of mathcalM_i vs. mathcalM_j can be stated as:","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"fracpi(mathcalM_i mid mathbfY)pi(mathcalM_j mid mathbfY) = fracpi(mathcalM_i)pi(mathcalM_j) mathrmBF_ij","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The term on the left hand side is the posterior odds of mathcalM_i vs. mathcalM_j, pi is the posterior probability, the first term on the right hand side is the prior odds of mathcalM_i vs. mathcalM_j, and mathrmBF_ij is the Bayes factor for mathcalM_i vs. mathcalM_j.  In the equation above, mathrmBF_ij functions as a conversion factor between prior odds and posterior odds. Thus,  the Bayes factor is as the factor by which prior odds must be updated in light of the data. This interpretation is important because demonstrates that the prior odds should be updated by the same factor even if there is disagreement over the prior odds. The Bayes factor can also be written as the ratio of marginal likelihoods as follows: ","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"mathrmBF_ij = fracf(mathbfY mid mathcalM_i)f(mathbfY mid mathcalM_j),","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"where f is the likelihood function of mathcalM_i, and the marginal likelihood of mathcalM_i is given by:","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"f(mathbfY mid mathcalM_i) = int_boldsymbolthetain boldsymbolTheta_i f(mathbfY mid boldsymboltheta mathcalM_i) pi(boldsymboltheta mid mathcalM_i) d boldsymboltheta.","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"In the equation above, boldsymbolTheta_i is the parameter space for mathcalM_i and boldsymboltheta in boldsymbolTheta is a vector of parameters. Under this interpretation, the marginal likelihood represents its average prior predictive ability of of mathcalM_i. One benefit of the Bayes factor is that the marginal likelihood accounts for model flexibility because the density of the prior distribution must be \"rationed\" across the parameter space (i.e., must integrate to 1). Consequentially, the predictions of a model with a diffuse distribution in a high dimensional parameter space will be penalized due to its low prior density. ","category":"page"},{"location":"bayes_factor/#Load-Packages","page":"Bayesian Model Comparison","title":"Load Packages","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Before proceeding, we will load the required packages.","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"using MCMCChains\nusing Pigeons\nusing Random\nusing TrueAndErrorModels\nusing Turing","category":"page"},{"location":"bayes_factor/#Define-Models","page":"Bayesian Model Comparison","title":"Define Models","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The following code blocks define the models along with their prior distributions using Turing.jl. Notice that the models are identical except constraints imposed on the error probabilities epsilon_i.","category":"page"},{"location":"bayes_factor/#TET4-Model","page":"Bayesian Model Comparison","title":"TET4 Model","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The TET4 model is described in detail on the page called model overview. The 4 in TET4 refers to the number of error probability parameters, which are described below. The TET4 model has four true preference state parameters which collectively form the joint probability distribution over preference states R_1R_2, R_1S_2 S_1R_2, S_1S_2, where R represents a true preference for the risky option, S represents a true preference for the safe option, and the subscript corresponds to choice set. The joint preference states are:","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"p_mathrmR_1R_2: the probability of prefering the risky option in both choice sets\np_mathrmR_1S_2: the probability of prefering the risky option in the first choice set and prefering the safe option in the second choice set\np_mathrmS_1R_2: the probability of prefering the safe option in the first choice set and prefering the risky option in the second choice set\np_mathrmS_1S_2: the probability of prefering the safe option in both choice sets","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"subject to the constraint that p_mathrmR_1R_2 + p_mathrmR_1S_2 + p_mathrmS_1R_2 + p_mathrmS_1S_2 = 1, and p_i geq 0 forall i. As its namesake implies, the TET4 model also has four error probability parameters:","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"epsilon_mathrmS_1: the error probability of selecting mathcalS_1 given that mathcalR_1 is prefered.\nepsilon_mathrmS_2: the error probability of selecting mathcalS_2 given that mathcalR_2 is prefered.\nepsilon_mathrmR_1: the error probability of selecting mathcalR_1 given that mathcalS_1 is prefered.\nepsilon_mathrmR_2: the error probability of selecting mathcalR_2 given that mathcalS_2 is prefered.","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The only constraint is that epsilon_i in 0 50forall i. The TET4 model is automatically loaded when Turing is loaded into your Julia session. The tet4_model function accepts a vector of response frequencies. The prior distributions are as follows:","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"mathbfp sim mathrmDirichlet(1111)","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"boldsymbolepsilon sim mathrmUniform(0 5)","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"where mathbfp is a vector of four preference state parameters, and boldsymbolepsilon is a vector of error probabilities. ","category":"page"},{"location":"bayes_factor/#TET1-Model","page":"Bayesian Model Comparison","title":"TET1 Model","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"As the name implies, the TET1 model constrains all error probability parameters to be equal:","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"epsilon = epsilon_mathrmS_1 = epsilon_mathrmS_S = epsilon_mathrmR_1 =epsilon_mathrmR_2","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Otherwise, TET1 and TET4 are identical. The TET1 model is also automatically loaded when Turing is loaded into your Julia session. The tet1_model function accepts a vector of response frequencies, and using the following prior distributions over the parameters:","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"mathbfp sim mathrmDirichlet(1111)","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"epsilon sim mathrmUniform(0 5)","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"where mathbfp is a vector of four preference state parameters, and error probability epsilon is a scalar. ","category":"page"},{"location":"bayes_factor/#Data-Generating-Model","page":"Bayesian Model Comparison","title":"Data-Generating Model","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"In our demonstration, we will use the TET1 as the data-generating model. In the code block below, we will create a model object and generate 2 simulated responses from all 100 simulated subjects for a total of 200 responses. In this model, we assume that the probability of a true preference state RR is relatively high, and the probability of other preference states decreases as they become more difference from RR:","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"p_mathrmR_1R_2 = 65\np_mathrmR_1S_2 = 15\np_mathrmS_1R_2 = 15\np_mathrmS_1S_2 = 05","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"In addition, our model assumes the error probabilities are constrained to be equal:","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"epsilon_mathrmS_1 = epsilon_mathrmS_S = epsilon_mathrmR_1 =epsilon_mathrmR_2 = 10","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Random.seed!(258)\ndist = TrueErrorModel(; p = [0.65, .15, .15, .05], ϵ = fill(.10, 4))\ndata = rand(dist, 200)","category":"page"},{"location":"bayes_factor/#Estimate-Marginal-Log-Likelihood","page":"Bayesian Model Comparison","title":"Estimate Marginal Log Likelihood","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The next step is to run the pigeons function to estimate the marginal log likelihood for each model. ","category":"page"},{"location":"bayes_factor/#TET4","page":"Bayesian Model Comparison","title":"TET4","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The code block below estimates the marginal log likelihood of the the TET4 model. This involves passing the tet4_model to the function pigeons along with the vector of response frequencies data.","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"pt_tet4 = pigeons(target=TuringLogPotential(tet4_model(data)), record=[traces])","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"────────────────────────────────────────────────────────────────────────────\n  scans        Λ      log(Z₁/Z₀)   min(α)     mean(α)    min(αₑ)   mean(αₑ) \n────────── ────────── ────────── ────────── ────────── ────────── ──────────\n        2       3.22      -47.6   0.000923      0.643          1          1 \n        4       1.86      -39.9      0.265      0.793          1          1 \n        8        3.6      -38.2      0.255        0.6          1          1 \n       16        3.2      -39.2      0.403      0.645          1          1 \n       32       3.51      -38.8       0.36       0.61          1          1 \n       64       3.56      -39.6      0.441      0.605          1          1 \n      128       3.78      -40.1      0.488       0.58          1          1 \n      256       3.63      -39.4      0.482      0.596          1          1 \n      512       3.61      -39.5      0.556      0.599          1          1 \n 1.02e+03       3.56      -39.2      0.577      0.604          1          1 \n────────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Below, we will change the numerical indices to more descriptive indices for ease of interpretation. The next line of code converts the output to an Chain object.","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"name_map = Dict(\n    \"p[1]\" => \"pᵣᵣ\",\n    \"p[2]\" => \"pᵣₛ\",\n    \"p[3]\" => \"pₛᵣ\",\n    \"p[4]\" => \"pₛₛ\",\n    \"ϵ[1]\" => \"ϵₛ₁\",\n    \"ϵ[2]\" => \"ϵₛ₂\",\n    \"ϵ[3]\" => \"ϵᵣ₁\",\n    \"ϵ[4]\" => \"ϵᵣ₂\",\n)\nchain_te4 = Chains(pt_tet4)\nchain_te4 = replacenames(chain_te4, name_map)","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"A summary of the MCMCChain is provided below.","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Chains MCMC chain (1024×9×1 Array{Float64, 3}):\n\nIterations        = 1:1:1024\nNumber of chains  = 1\nSamples per chain = 1024\nparameters        = pᵣᵣ, pᵣₛ, pₛᵣ, pₛₛ, ϵₛ₁, ϵₛ₂, ϵᵣ₁, ϵᵣ₂\ninternals         = log_density\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   ess_per_sec \n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64       Missing \n\n         pᵣᵣ    0.5768    0.0824    0.0039   449.2267   570.8385    1.0027       missing\n         pᵣₛ    0.1820    0.0662    0.0033   391.3331   750.0271    1.0000       missing\n         pₛᵣ    0.1787    0.0579    0.0026   523.1174   740.9073    1.0002       missing\n         pₛₛ    0.0625    0.0297    0.0012   618.7097   755.8075    0.9995       missing\n         ϵₛ₁    0.0517    0.0314    0.0014   529.0317   866.9172    0.9995       missing\n         ϵₛ₂    0.0571    0.0342    0.0017   418.1905   657.3602    1.0010       missing\n         ϵᵣ₁    0.1995    0.1077    0.0048   514.3591   868.8844    1.0006       missing\n         ϵᵣ₂    0.2706    0.1235    0.0065   372.7194   763.7186    1.0005       missing\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n\n         pᵣᵣ    0.4293    0.5165    0.5762    0.6383    0.7335\n         pᵣₛ    0.0712    0.1317    0.1765    0.2275    0.3180\n         pₛᵣ    0.0820    0.1335    0.1760    0.2202    0.2987\n         pₛₛ    0.0179    0.0411    0.0576    0.0808    0.1294\n         ϵₛ₁    0.0033    0.0245    0.0511    0.0754    0.1104\n         ϵₛ₂    0.0033    0.0282    0.0566    0.0840    0.1238\n         ϵᵣ₁    0.0162    0.1078    0.2056    0.2830    0.3887\n         ϵᵣ₂    0.0232    0.1705    0.2894    0.3699    0.4639","category":"page"},{"location":"bayes_factor/#TE1","page":"Bayesian Model Comparison","title":"TE1","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"As we did above, we will estimate the marginal log likelihood by passing tet1_model to the functionpigeons. ","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"pt_tet1 = pigeons(target=TuringLogPotential(te1_model(data)), record=[traces])","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"────────────────────────────────────────────────────────────────────────────\n  scans        Λ      log(Z₁/Z₀)   min(α)     mean(α)    min(αₑ)   mean(αₑ) \n────────── ────────── ────────── ────────── ────────── ────────── ──────────\n        2       3.18      -69.3   1.04e-16      0.647          1          1 \n        4       2.11      -41.9    0.00298      0.766          1          1 \n        8       3.41      -39.2      0.226      0.621          1          1 \n       16       2.96      -38.6      0.364      0.671          1          1 \n       32       3.71      -37.6      0.459      0.588          1          1 \n       64       3.55      -38.3      0.505      0.605          1          1 \n      128       3.42        -38      0.487       0.62          1          1 \n      256       3.48      -38.1      0.556      0.613          1          1 \n      512       3.28      -37.7      0.593      0.635          1          1 \n 1.02e+03       3.41        -38      0.578      0.621          1          1 \n────────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"In the code block below, we will rename the parameters, and convert the output to an Chain object","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"name_map = Dict(\n    \"p[1]\" => \"pᵣᵣ\",\n    \"p[2]\" => \"pᵣₛ\",\n    \"p[3]\" => \"pₛᵣ\",\n    \"p[4]\" => \"pₛₛ\",\n)\nchain_te1 = Chains(pt_tet1)\nchain_te1 = replacenames(chain_te1, name_map)","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The output below provides a summary of the chain.","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Chains MCMC chain (1024×6×1 Array{Float64, 3}):\n\nIterations        = 1:1:1024\nNumber of chains  = 1\nSamples per chain = 1024\nparameters        = pᵣᵣ, pᵣₛ, pₛᵣ, pₛₛ, ϵ\ninternals         = log_density\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ess_per_sec \n      Symbol   Float64   Float64   Float64     Float64     Float64   Float64       Missing \n\n         pᵣᵣ    0.7077    0.0351    0.0011   1106.2442   1055.5828    1.0000       missing\n         pᵣₛ    0.1178    0.0261    0.0009    908.2753    965.3276    1.0009       missing\n         pₛᵣ    0.1408    0.0268    0.0008   1036.7903    867.0191    0.9992       missing\n         pₛₛ    0.0338    0.0140    0.0005    891.6153   1059.1575    1.0031       missing\n           ϵ    0.0874    0.0115    0.0004    952.5670    803.6060    0.9995       missing\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n\n         pᵣᵣ    0.6364    0.6843    0.7065    0.7329    0.7712\n         pᵣₛ    0.0717    0.0993    0.1165    0.1344    0.1746\n         pₛᵣ    0.0923    0.1213    0.1402    0.1589    0.1964\n         pₛₛ    0.0120    0.0235    0.0318    0.0422    0.0662\n           ϵ    0.0668    0.0795    0.0867    0.0947    0.1114","category":"page"},{"location":"bayes_factor/#Extract-marginal-log-likelihood","page":"Bayesian Model Comparison","title":"Extract marginal log likelihood","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"In the following code block, the function stepping_stone extracts that marginal log likelihood for each model:","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"mll_tet1 = stepping_stone(pt_tet1)\nmll_tet4 = stepping_stone(pt_tet4)","category":"page"},{"location":"bayes_factor/#Compute-the-Bayes-Factor","page":"Bayesian Model Comparison","title":"Compute the Bayes Factor","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The bayes factor is obtained by exponentiating the difference between marginal log likelihoods. Recall that TET1 was the data-generating model.  As expected, the value of 3.39 indicates that the data are 3.39 times more likely under the data-generating model, TET1, than TET4.","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"bf = exp(mll_tet1 - mll_tet4)","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"3.3948019100884617","category":"page"},{"location":"bayes_factor/#References","page":"Bayesian Model Comparison","title":"References","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Birnbaum, M. H., & Quispe-Torreblanca, E. G. (2018). TEMAP2. R: True and error model analysis program in R. Judgment and Decision Making, 13(5), 428-440.","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Lee, M. D. (2018). Bayesian methods for analyzing true-and-error models. Judgment and Decision making, 13(6), 622-635.","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Syed, S., Bouchard-Côté, A., Deligiannidis, G., & Doucet, A. (2022). Non-reversible parallel tempering: a scalable highly parallel MCMC scheme. Journal of the Royal Statistical Society Series B: Statistical Methodology, 84(2), 321-350.","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"<img src=\"https://raw.githubusercontent.com/itsdfish/TrueAndErrorModels.jl/gh-pages/dev/assets/logo_readme.png\" alt=\"drawing\" width=\"900\"/>","category":"page"},{"location":"overview/#Model-Overview","page":"Model Overview","title":"Model Overview","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"One challenge in evaluating theories of decision making is that data likely reflect a mixture of true preferences and response error. Suppose a person selects risky option mathcalR over safe option mathcalS. This response could arise through two different pathways. First, a person may truely prefer mathcalR to mathcalS and report his or her preferences accurately. Alternatively, this person may truely mathcalS, but select mathcalR by accident. True and Error Theory (TET; Birnbaum,  & Quispe-Torreblanca, 2018) provides a mathematical framework for distinguishing true preferences from errors in reporting due to various sources, such as trembling hand, failures of memory and/or reasoning, and lapses of attention. ","category":"page"},{"location":"overview/#Task","page":"Model Overview","title":"Task","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"TET can be applied to a wide variety of tasks in which subjects make repeated decisions from the same choice sets. As a simple example, we will consider a decision making task in which subjects choose between two sets of options: ","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"mathcalC_1 = mathcalR_1mathcalS_1","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"and ","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"mathcalC_2 = mathcalR_2mathcalS_2,","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"where mathcalR represents a risky gamble and mathcalS represents a safe gamble. In general, a generic gamble mathcalG is defined by the discrete payoff distribution:","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"mathcalG = (x_1 p_1 dots x_n p_n) ","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"where outcome x_i occurs with probability p_i. The key difference between gambles mathcalR and mathcalS is that mathrmVarmathcalR  mathrmVarmathcalS. An important requirement for TET is that subjects select an option from both choice sets at least twice within the same session. Assuming two replications each, the resulting joint response set contains 16 patterns: ","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"(mathcalR_1mathcalR_2mathcalR_1mathcalR_2)(mathcalR_1mathcalR_2mathcalR_1mathcalS_2) dots (mathcalS_1mathcalS_2mathcalS_1mathcalS_2).","category":"page"},{"location":"overview/#True-and-Error-Theory","page":"Model Overview","title":"True and Error Theory","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"As noted above, TET provides a mathematical framework for distinguishing between true preferences and errors in reporting errors due to various sources, such as trembling hand, failures of memory and/or reasoning, and lapses of attention. According to TET, there are four possible preference states, one for each possible option: RR, RS, SR, SS. For example, preference state SR indicates a person pefers the safe option in the first choice set, and the risky option in the second choice set. If this person responded without error, his or her response pattern would be (mathcalS_1mathcalR_2mathcalS_1mathcalR_2).","category":"page"},{"location":"overview/#Parameters","page":"Model Overview","title":"Parameters","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"The full TET model contains 8 parameters in total: four preference state parameters and four error parameters. Sometimes this model is called the TET4 model, with 4 signifying the number of error parameters. Four of the parameters represent the joint probability of the four true preference states:","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"p_mathrmR_1R_2: the probability of prefering the risky option in both choice sets\np_mathrmR_1S_2: the probability of prefering the risky option in the first choice set and prefering the safe option in the second choice set\np_mathrmS_1R_2: the probability of prefering the safe option in the first choice set and prefering the risky option in the second choice set\np_mathrmS_1S_2: the probability of prefering the safe option in both choice sets","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"subject to the constraint that p_mathrmR_1R_2 + p_mathrmR_1S_2 + p_mathrmS_1R_2 + p_mathrmS_1S_2 = 1.","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"The remaining four parameters correspond to error probabilities:","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"epsilon_mathrmS_1: the error probability of selecting mathcalS_1 given that mathcalR_1 is prefered.\nepsilon_mathrmS_2: the error probability of selecting mathcalS_2 given that mathcalR_2 is prefered.\nepsilon_mathrmR_1: the error probability of selecting mathcalR_1 given that mathcalS_1 is prefered.\nepsilon_mathrmR_2: the error probability of selecting mathcalR_2 given that mathcalS_2 is prefered.","category":"page"},{"location":"overview/#Structure","page":"Model Overview","title":"Structure","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"The TET model is structured as a multinomial processing tree in which nodes correspond to cognitive states or processes, and branches correspond to transition probabilities. In total, the TET model has 16 equations, corresponding to the 16 possible response patterns. Each equation is displayed below. As an example, consider the first equation, which corresonds to response pattern (mathcalR_1mathcalR_2,mathcalR_1mathcalR_2). Although the risky option was selected for each decision, the TET model proposes that the response pattern could have been generated from any of the four preference states enumerated above. Each possible preference state occurs with a given probability and produces the observed choice pattern with a combination of correct and error responses. As an example, consider the first term in theta_1 in which the assumed preference state is RR:","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"p_mathrmR_1R_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2)","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"Under this assumption, each response is produced by correctly reporting the preference state. Hence, all four terms with epsilon_i use the complementary probability 1 - epsilon_i. Now consider the fourth term in which the assumed preference state is SS: ","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"p_mathrmS_1S_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"Under this alternative assumption, all four responses are produced through error. A similar line of reasoning is used to define the remaining equations below.","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{R}_2,\\mathcal{R}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalR_1mathcalR_2,mathcalR_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_1 =     p_mathrmR_1R_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmR_1S_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 +       p_mathrmS_1R_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmS_1S_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{R}_2,\\mathcal{R}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalR_1mathcalR_2,mathcalR_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_2 =     p_mathrmR_1R_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 +       p_mathrmR_1S_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) +       p_mathrmS_1R_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 +       p_mathrmS_1S_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{R}_2,\\mathcal{S}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalR_1mathcalR_2,mathcalS_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_3 =     p_mathrmR_1R_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmR_1S_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 +       p_mathrmS_1R_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmS_1S_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{R}_2,\\mathcal{S}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalR_1mathcalR_2,mathcalS_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_4 =     p_mathrmR_1R_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 +       p_mathrmR_1S_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) +       p_mathrmS_1R_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 +       p_mathrmS_1S_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{S}_2,\\mathcal{R}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalR_1mathcalS_2,mathcalR_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_5 =     p_mathrmR_1R_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmR_1S_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 +       p_mathrmS_1R_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmS_1S_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{S}_2,\\mathcal{R}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalR_1mathcalS_2,mathcalR_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_6 =     p_mathrmR_1R_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 +       p_mathrmR_1S_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) +       p_mathrmS_1R_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 +       p_mathrmS_1S_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{S}_2,\\mathcal{S}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalR_1mathcalS_2,mathcalS_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_7 =     p_mathrmR_1R_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmR_1S_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 +       p_mathrmS_1R_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmS_1S_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{S}_2,\\mathcal{S}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalR_1mathcalS_2,mathcalS_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_8 =     p_mathrmR_1R_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 +       p_mathrmR_1S_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) +       p_mathrmS_1R_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 +       p_mathrmS_1S_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{R}_2,\\mathcal{R}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalS_1mathcalR_2,mathcalR_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_9 =     p_mathrmR_1R_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmR_1S_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 +       p_mathrmS_1R_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmS_1S_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{R}_2,\\mathcal{R}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalS_1mathcalR_2,mathcalR_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_10 =     p_mathrmR_1R_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 +       p_mathrmR_1S_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) +       p_mathrmS_1R_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 +       p_mathrmS_1S_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{R}_2,\\mathcal{S}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalS_1mathcalR_2,mathcalS_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_11 =     p_mathrmR_1R_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmR_1S_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 +       p_mathrmS_1R_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmS_1S_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{R}_2,\\mathcal{S}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalS_1mathcalR_2,mathcalS_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_12 =     p_mathrmR_1R_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 +       p_mathrmR_1S_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) +       p_mathrmS_1R_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 +       p_mathrmS_1S_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{S}_2,\\mathcal{R}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalS_1mathcalS_2,mathcalR_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_13 =     p_mathrmR_1R_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmR_1S_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 +       p_mathrmS_1R_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmS_1S_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{S}_2,\\mathcal{R}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalS_1mathcalS_2,mathcalR_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_14 =     p_mathrmR_1R_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 +       p_mathrmR_1S_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) +       p_mathrmS_1R_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 +       p_mathrmS_1S_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{S}_2,\\mathcal{S}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalS_1mathcalS_2,mathcalS_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_15 =     p_mathrmR_1R_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmR_1S_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 +       p_mathrmS_1R_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmS_1S_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{S}_2,\\mathcal{S}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalS_1mathcalS_2,mathcalS_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_16 =     p_mathrmR_1R_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 +       p_mathrmR_1S_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) +       p_mathrmS_1R_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 +       p_mathrmS_1S_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#References","page":"Model Overview","title":"References","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"Birnbaum, M. H., & Quispe-Torreblanca, E. G. (2018). TEMAP2. R: True and error model analysis program in R. Judgment and Decision Making, 13(5), 428-440.","category":"page"},{"location":"","page":"Home","title":"Home","text":"<img src=\"https://raw.githubusercontent.com/itsdfish/TrueAndErrorModels.jl/gh-pages/dev/assets/logo_readme.png\" alt=\"drawing\" width=\"900\"/>","category":"page"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The purpose of this package is to provide an implementation of True and Error Theory (TET; Birnbaum,  & Quispe-Torreblanca, 2018) in the Julia programming language. TET provides a mathematical framework for distinguishing between true preferences and errors in option evaluation and selection. For example, a person who selects risky option mathcalR over safe option mathcalS may truely prefer mathcalR, or may truely prefer mathcalS, but committed an error during the evaluation process. For more details, see the section titled Model Overview.","category":"page"},{"location":"#Key-Features","page":"Home","title":"Key Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"One of the most valuable benefits of TrueAndErrorModels.jl is its seemless integration with the Julia ecosystem. Key examples include","category":"page"},{"location":"","page":"Home","title":"Home","text":"Distributions.jl: a common interface for probability distributions, including probability density functions, cumulative distribution functions, means etc. \nTuring.jl: an ecosystem for Bayesian parameter estimation, maximum likelihood estimation, variational inference and more.\nPigeons.jl: a package for Bayes factors and Bayesian parameter estimation, specializing with intractible, multimodal posterior distributions. Pigeons.jl is compatible with Turing.jl.","category":"page"},{"location":"#References","page":"Home","title":"References","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Birnbaum, M. H., & Quispe-Torreblanca, E. G. (2018). TEMAP2. R: True and error model analysis program in R. Judgment and Decision Making, 13(5), 428-440.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Lee, M. D. (2018). Bayesian methods for analyzing true-and-error models. Judgment and Decision Making, 13(6), 622-635.","category":"page"}]
}
