var documenterSearchIndex = {"docs":
[{"location":"parameter_estimation/#A-Simple-Turing-Model","page":"Bayesian Parameter Estimation","title":"A Simple Turing Model","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"It is possible to use Turing.jl to perform Bayesian parameter estimation on models defined in SequentialSamplingModels.jl. Below, we show you how to estimate the parameters for the Linear Ballistic Accumulator (LBA) and to use it to estimate effects.","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Note that you can easily swap the LBA model from this example for other SSM models simply by changing the names of the parameters.","category":"page"},{"location":"parameter_estimation/#Load-Packages","page":"Bayesian Parameter Estimation","title":"Load Packages","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The first step is to load the required packages. You will need to install each package in your local environment in order to run the code locally. We will also set a random number generator so that the results are reproducible.","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"using Turing\nusing TrueAndErrorModels\nusing Random\nusing StatsPlots\nusing Random\n\nRandom.seed!(25044)","category":"page"},{"location":"parameter_estimation/#Generate-Data","page":"Bayesian Parameter Estimation","title":"Generate Data","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"We will use the LBA distribution to simulate data (100 trials) with fixed parameters (those we want to recover only from the data using Bayesian modeling).","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"# Generate some data with known parameters\ndist = TrueErrorModel(; p = [0.60, .30, .05, .05], ϵ = fill(.10, 4))\ndata = rand(dist, 200)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"16-element Vector{Int64}:\n 80\n 13\n  8\n  1\n 16\n 35\n  ⋮\n  8\n  2\n  3\n  9\n  1\n  9","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The rand() function will sample random draws from the distribution, and store that into a named tuple of 2 vectors (one for choice and one for rt). The individual vectors can be accessed by their names using data.choice and data.rt.","category":"page"},{"location":"parameter_estimation/#Specify-Turing-Model","page":"Bayesian Parameter Estimation","title":"Specify Turing Model","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The code snippet below defines a model in Turing. The model function accepts a tuple containing a vector of choices and a vector of reaction times. The sampling statements define the prior distributions for each parameter. The non-decision time parameter tau must be founded by the minimum reaction time, min_rt. The last sampling statement defines the likelihood of the data given the sampled parameter values.","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"@model function model(data)\n    p ~ Dirichlet(fill(1, 4))\n    ϵ ~ filldist(Uniform(0, .5), 4)\n    data ~ TrueErrorModel(p, ϵ)\nend","category":"page"},{"location":"parameter_estimation/#Estimate-the-Parameters","page":"Bayesian Parameter Estimation","title":"Estimate the Parameters","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Finally, we perform parameter estimation with sample(), which takes the model, and details about the sampling algorithm:","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"model(data): the Turing model with data passed\nNUTS(1000, .65): a sampler object for the No U-Turn Sampler for 1000 warmup samples.\nMCMCThreads(): instructs Turing to run each chain on a separate thread\nn_iterations: the number of iterations performed after warmup\nn_chains: the number of chains","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"# Estimate parameters\nchains = sample(model(data), NUTS(1000, .65), MCMCThreads(), 1000, 4)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Chains MCMC chain (1000×20×4 Array{Float64, 3}):\n\nIterations        = 1001:1:2000\nNumber of chains  = 4\nSamples per chain = 1000\nWall duration     = 2.11 seconds\nCompute duration  = 6.21 seconds\nparameters        = p[1], p[2], p[3], p[4], ϵ[1], ϵ[2], ϵ[3], ϵ[4]\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ess_per_sec \n      Symbol   Float64   Float64   Float64     Float64     Float64   Float64       Float64 \n\n        p[1]    0.5310    0.0844    0.0021   1611.5020   1931.9193    1.0008      259.5011\n        p[2]    0.2536    0.0725    0.0017   1882.4309   2316.0608    1.0006      303.1290\n        p[3]    0.1033    0.0512    0.0013   1520.5778   2258.6363    1.0006      244.8596\n        p[4]    0.1121    0.0443    0.0010   1999.5107   2448.4595    1.0012      321.9824\n        ϵ[1]    0.0654    0.0328    0.0008   1521.5648   1140.1998    1.0025      245.0185\n        ϵ[2]    0.0984    0.0479    0.0011   1750.7039   1641.4243    1.0008      281.9169\n        ϵ[3]    0.3015    0.1241    0.0030   1641.3979   1858.2680    1.0034      264.3153\n        ϵ[4]    0.1382    0.0810    0.0019   1744.5089   1863.3155    1.0014      280.9193\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n\n        p[1]    0.3662    0.4706    0.5323    0.5931    0.6851\n        p[2]    0.1378    0.1994    0.2444    0.2985    0.4119\n        p[3]    0.0276    0.0635    0.0967    0.1349    0.2171\n        p[4]    0.0427    0.0793    0.1064    0.1404    0.2091\n        ϵ[1]    0.0060    0.0410    0.0655    0.0891    0.1292\n        ϵ[2]    0.0087    0.0622    0.1018    0.1343    0.1841\n        ϵ[3]    0.0438    0.2090    0.3166    0.4040    0.4880\n        ϵ[4]    0.0116    0.0714    0.1318    0.1998    0.2997","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"name_map = Dict(\n    \"p[1]\" => \"pᵣᵣ\",\n    \"p[2]\" => \"pᵣₛ\",\n    \"p[3]\" => \"pₛᵣ\",\n    \"p[4]\" => \"pₛₛ\",\n    \"ϵ[1]\" => \"ϵᵣₛ₁\",\n    \"ϵ[2]\" => \"ϵᵣₛ₂\",\n    \"ϵ[3]\" => \"ϵₛᵣ₁\",\n    \"ϵ[4]\" => \"ϵₛᵣ₂\",\n)\nchains = replacenames(chains, name_map)","category":"page"},{"location":"parameter_estimation/#Posterior-Summary","page":"Bayesian Parameter Estimation","title":"Posterior Summary","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"We can compute a description of the posterior distributions.","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"# Summarize posteriors\nsummarystats(chains)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Summary Statistics\n  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ess_per_sec \n      Symbol   Float64   Float64   Float64     Float64     Float64   Float64       Float64 \n\n         pᵣᵣ    0.5310    0.0844    0.0021   1611.5020   1931.9193    1.0008      259.5011\n         pᵣₛ    0.2536    0.0725    0.0017   1882.4309   2316.0608    1.0006      303.1290\n         pₛᵣ    0.1033    0.0512    0.0013   1520.5778   2258.6363    1.0006      244.8596\n         pₛₛ    0.1121    0.0443    0.0010   1999.5107   2448.4595    1.0012      321.9824\n        ϵᵣₛ₁    0.0654    0.0328    0.0008   1521.5648   1140.1998    1.0025      245.0185\n        ϵᵣₛ₂    0.0984    0.0479    0.0011   1750.7039   1641.4243    1.0008      281.9169\n        ϵₛᵣ₁    0.3015    0.1241    0.0030   1641.3979   1858.2680    1.0034      264.3153\n        ϵₛᵣ₂    0.1382    0.0810    0.0019   1744.5089   1863.3155    1.0014      280.9193","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"As you can see, based on the mean values of the posterior distributions, the original parameters (ν=[3.0, 2.0], A = .8, k = .2, τ = .3) are successfully recovered from the data (the accuracy would increase with more data).","category":"page"},{"location":"parameter_estimation/#Evaluation","page":"Bayesian Parameter Estimation","title":"Evaluation","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"It is important to verify that the chains converged. We see that the chains converged according to hatr leq 105, and the trace plots below show that the chains look like \"hairy caterpillars\", which indicates the chains did not get stuck. As expected, the posterior distributions are close to the data generating parameter values.","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"plot(chains)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"(Image: )","category":"page"},{"location":"bayes_factor/#Computing-the-Bayes-Factor","page":"Bayesian Model Comparison","title":"Computing the Bayes Factor","text":"","category":"section"},{"location":"bayes_factor/#Overview","page":"Bayesian Model Comparison","title":"Overview","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"In this tutorial, we will use the Bayes factor to compare the evidence for one model relative to another reference model. Computing the Bayes factor is challenging because it requires integrating the log likelihood over the model parameters. One method for approximating this complex integral is non-reversible parallel tempering (Bouchard-Côté et al., 2022) using  Pigeons.jl. ","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"In the tutorial below, we will compare two models which differ only in terms of assumptions about drift rate variability: the LBA and the RDM. The LBA assumes that the drift rate varies across trials and is otherwise deterministic, whereas the RDM assumes the drift rate varies within a trial as Gaussian noise, but not across trials. The difference between the models can be visualized with Plots.jl:","category":"page"},{"location":"bayes_factor/#Load-Packages","page":"Bayesian Model Comparison","title":"Load Packages","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Before proceeding, we will load the required packages.","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"using MCMCChains\nusing Pigeons\nusing Random\nusing TrueAndErrorModels\nusing Turing","category":"page"},{"location":"bayes_factor/#Data-Generating-Model","page":"Bayesian Model Comparison","title":"Data-Generating Model","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The next step is to generate simulated data for comparing the models. Here, we will assume that the LBA is the true data generating model:","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Random.seed!(541)\ndist = TrueErrorModel(; p = [0.60, .30, .05, .05], ϵ = fill(.10, 4))\ndata = rand(dist, 200)","category":"page"},{"location":"bayes_factor/#Define-Models","page":"Bayesian Model Comparison","title":"Define Models","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The following code blocks define the models along with their prior distributions using Turing.jl. Notice that the models are identical except for the log likelihood function.","category":"page"},{"location":"bayes_factor/#RDM","page":"Bayesian Model Comparison","title":"RDM","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"@model function te4_model(data)\n    p ~ Dirichlet(fill(1, 4))\n    ϵ ~ filldist(Uniform(0, .5), 4)\n    data ~ TrueErrorModel(p, ϵ)\nend","category":"page"},{"location":"bayes_factor/#LBA","page":"Bayesian Model Comparison","title":"LBA","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"@model function te1_model(data)\n    p ~ Dirichlet(fill(1, 4))\n    ϵ ~ Uniform(0, .5)\n    data ~ TrueErrorModel(p, fill(ϵ, 4))\nend","category":"page"},{"location":"bayes_factor/#Estimate-Marginal-Log-Likelihood","page":"Bayesian Model Comparison","title":"Estimate Marginal Log Likelihood","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The next step is to run the pigeons function to estimate the marginal log likelihood for each model. ","category":"page"},{"location":"bayes_factor/#TE4","page":"Bayesian Model Comparison","title":"TE4","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"pt_te4 = pigeons(target=TuringLogPotential(te4_model(data)), record=[traces])","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"────────────────────────────────────────────────────────────────────────────\n  scans        Λ      log(Z₁/Z₀)   min(α)     mean(α)    min(αₑ)   mean(αₑ) \n────────── ────────── ────────── ────────── ────────── ────────── ──────────\n        2       3.25      -52.7    0.00244      0.639          1          1 \n        4       2.19      -38.7      0.152      0.757          1          1 \n        8       2.71      -42.3    0.00281      0.698          1          1 \n       16       3.81      -40.4      0.262      0.576          1          1 \n       32       3.41      -40.8      0.464      0.621          1          1 \n       64       3.76      -40.9      0.247      0.582          1          1 \n      128       3.77      -40.4      0.489      0.581          1          1 \n      256       3.66      -40.6      0.519      0.594          1          1 \n      512       3.52      -40.4      0.559      0.609          1          1 \n 1.02e+03        3.6      -40.6      0.572        0.6          1          1 \n────────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"name_map = Dict(\n    \"p[1]\" => \"pᵣᵣ\",\n    \"p[2]\" => \"pᵣₛ\",\n    \"p[3]\" => \"pₛᵣ\",\n    \"p[4]\" => \"pₛₛ\",\n    \"ϵ[1]\" => \"ϵᵣₛ₁\",\n    \"ϵ[2]\" => \"ϵᵣₛ₂\",\n    \"ϵ[3]\" => \"ϵₛᵣ₁\",\n    \"ϵ[4]\" => \"ϵₛᵣ₂\",\n)\nchain_te4 = Chains(pt_te4)\nchain_te4 = replacenames(chain_te4, name_map)","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Chains MCMC chain (1024×9×1 Array{Float64, 3}):\n\nIterations        = 1:1:1024\nNumber of chains  = 1\nSamples per chain = 1024\nparameters        = pᵣᵣ, pᵣₛ, pₛᵣ, pₛₛ, ϵᵣₛ₁, ϵᵣₛ₂, ϵₛᵣ₁, ϵₛᵣ₂\ninternals         = log_density\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   ess_per_sec \n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64       Missing \n\n         pᵣᵣ    0.5154    0.0709    0.0032   517.0050   691.9324    0.9991       missing\n         pᵣₛ    0.2974    0.0583    0.0028   439.8920   630.1510    1.0065       missing\n         pₛᵣ    0.1325    0.0495    0.0021   553.5050   793.0310    1.0001       missing\n         pₛₛ    0.0547    0.0330    0.0014   574.1878   814.2801    0.9994       missing\n        ϵᵣₛ₁    0.0524    0.0283    0.0013   494.4657   784.5909    1.0016       missing\n        ϵᵣₛ₂    0.0711    0.0378    0.0017   483.4845   751.6983    1.0031       missing\n        ϵₛᵣ₁    0.2656    0.1333    0.0058   555.4617   964.3257    0.9996       missing\n        ϵₛᵣ₂    0.1222    0.0707    0.0032   544.5935   788.4338    0.9999       missing\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n\n         pᵣᵣ    0.3873    0.4639    0.5116    0.5646    0.6550\n         pᵣₛ    0.1927    0.2561    0.2955    0.3364    0.4127\n         pₛᵣ    0.0570    0.0922    0.1271    0.1650    0.2401\n         pₛₛ    0.0090    0.0288    0.0494    0.0753    0.1312\n        ϵᵣₛ₁    0.0035    0.0300    0.0535    0.0732    0.1044\n        ϵᵣₛ₂    0.0052    0.0415    0.0712    0.0994    0.1430\n        ϵₛᵣ₁    0.0178    0.1585    0.2810    0.3754    0.4787\n        ϵₛᵣ₂    0.0081    0.0602    0.1223    0.1762    0.2554","category":"page"},{"location":"bayes_factor/#TE1","page":"Bayesian Model Comparison","title":"TE1","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"pt_te1 = pigeons(target=TuringLogPotential(te1_model(data)), record=[traces])","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"────────────────────────────────────────────────────────────────────────────\n  scans        Λ      log(Z₁/Z₀)   min(α)     mean(α)    min(αₑ)   mean(αₑ) \n────────── ────────── ────────── ────────── ────────── ────────── ──────────\n        2          5      -64.5   1.25e-15      0.444          1          1 \n        4       2.66      -43.1   1.83e-05      0.704          1          1 \n        8       4.18      -37.1      0.293      0.536          1          1 \n       16        3.2      -38.2      0.395      0.645          1          1 \n       32        3.1      -37.6      0.523      0.656          1          1 \n       64        3.4      -38.2      0.421      0.623          1          1 \n      128       3.39      -38.2      0.539      0.623          1          1 \n      256       3.22      -38.2      0.542      0.643          1          1 \n      512       3.39      -38.3      0.571      0.624          1          1 \n 1.02e+03       3.44      -38.4      0.575      0.617          1          1 \n────────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"name_map = Dict(\n    \"p[1]\" => \"pᵣᵣ\",\n    \"p[2]\" => \"pᵣₛ\",\n    \"p[3]\" => \"pₛᵣ\",\n    \"p[4]\" => \"pₛₛ\",\n)\nchain_te1 = Chains(pt_te1)\nchain_te1 = replacenames(chain_te1, name_map)","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Chains MCMC chain (1024×6×1 Array{Float64, 3}):\n\nIterations        = 1:1:1024\nNumber of chains  = 1\nSamples per chain = 1024\nparameters        = pᵣᵣ, pᵣₛ, pₛᵣ, pₛₛ, ϵ\ninternals         = log_density\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk   ess_tail      rhat   ess_per_sec \n      Symbol   Float64   Float64   Float64     Float64    Float64   Float64       Missing \n\n         pᵣᵣ    0.5839    0.0387    0.0013    893.7920   857.1908    1.0015       missing\n         pᵣₛ    0.3035    0.0341    0.0012    866.3328   818.7203    1.0042       missing\n         pₛᵣ    0.0884    0.0223    0.0007    886.3091   967.7621    0.9998       missing\n         pₛₛ    0.0241    0.0135    0.0004   1056.1839   962.0659    1.0000       missing\n           ϵ    0.0838    0.0108    0.0004    967.7828   974.2063    0.9992       missing\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n\n         pᵣᵣ    0.5081    0.5581    0.5851    0.6097    0.6611\n         pᵣₛ    0.2399    0.2821    0.3048    0.3262    0.3730\n         pₛᵣ    0.0489    0.0727    0.0873    0.1026    0.1350\n         pₛₛ    0.0054    0.0143    0.0215    0.0314    0.0571\n           ϵ    0.0644    0.0763    0.0831    0.0902    0.1065","category":"page"},{"location":"bayes_factor/#Extract-marginal-log-likelihood","page":"Bayesian Model Comparison","title":"Extract marginal log likelihood","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"In the following code block, the function stepping_stone extracts that marginal log likelihood:","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"mll_te1 = stepping_stone(pt_te1)\nmll_te4 = stepping_stone(pt_te4)","category":"page"},{"location":"bayes_factor/#Compute-the-Bayes-Factor","page":"Bayesian Model Comparison","title":"Compute the Bayes Factor","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The bayes factor is obtained by exponentiating the difference between marginal log likelihoods. The value of 1.21 indicates that the LBA is 1.21 times more likely to have generated the data. ","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"bf = exp(mll_te1 - mll_te4)","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"9.096485357929172","category":"page"},{"location":"bayes_factor/#References","page":"Bayesian Model Comparison","title":"References","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Syed, S., Bouchard-Côté, A., Deligiannidis, G., & Doucet, A. (2022). Non-reversible parallel tempering: a scalable highly parallel MCMC scheme. Journal of the Royal Statistical Society Series B: Statistical Methodology, 84(2), 321-350.","category":"page"},{"location":"#TrueAndErrorModels.jl","page":"Home","title":"TrueAndErrorModels.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for TrueAndErrorModels.jl","category":"page"}]
}
