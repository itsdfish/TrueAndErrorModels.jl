var documenterSearchIndex = {"docs":
[{"location":"parameter_estimation/#Bayesian-Parameter-Estimation","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The purpose of this tutorial is to demonstrate how to perform Bayesian parameter estimation of the True and Error model (TET; Birnbaum & Quispe-Torreblanca, 2018) using the Turing.jl package. ","category":"page"},{"location":"parameter_estimation/#Load-Packages","page":"Bayesian Parameter Estimation","title":"Load Packages","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The first step is to load the required packages. You will need to install each package in your local environment in order to run the code locally. We will also set a random number generator so that the results are reproducible.","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"using Turing\nusing TrueAndErrorModels\nusing Random\nusing StatsPlots\nRandom.seed!(25044)","category":"page"},{"location":"parameter_estimation/#Generate-Data","page":"Bayesian Parameter Estimation","title":"Generate Data","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"In the code block below, we will create a model object and generate 2 simulated responses from 100 simulated subjects for a total of 200 responses. For this model, we assume that the probability of a true preference state RR is relatively high, and the probability of other preference states decreases as they become more difference from RR:","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"p_mathrmRR = 65\np_mathrmRS = 15\np_mathrmSR = 15\np_mathrmSS = 05","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"In addition, our model assumes the error probabilities are constrained to be equal:","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"epsilon_mathrmS_1 = epsilon_mathrmS_S = epsilon_mathrmR_1 =epsilon_mathrmR_2 = 10","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"# Generate some data with known parameters\ndist = TrueErrorModel(; p = [0.65, .15, .15, .05], ϵ = fill(.10, 4))\ndata = rand(dist, 200)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"16-element Vector{Int64}:\n 87\n 11\n 13\n  1\n 13\n 18\n  0\n  3\n 10\n  2\n 18\n  1\n  4\n  5\n  2\n 12","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"In the output above, we see the response vector has 16 elements, which correspond to response frequencies for the 16 response patterns:","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"(mathcalR_1mathcalR_2mathcalR_1mathcalR_2)(mathcalR_1mathcalR_2mathcalR_1mathcalS_2) dots (mathcalS_1mathcalS_2mathcalS_1mathcalS_2)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"where mathcalR and mathcalS correspond to risky and safe options, respectively, and the subscript indexes the choice set.  ","category":"page"},{"location":"parameter_estimation/#Specify-Turing-Model","page":"Bayesian Parameter Estimation","title":"Specify Turing Model","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The code snippet below defines a model in Turing. The model function accepts a vector of response frequencies. The preference state vector mathbfp is sampled from a uniform Dirichlet distribution, which ensures that the four elements p_mathrmRR + p_mathrmRS + p_mathrmSR + p_mathrmSS = 1. All error probability parameters are constrained to be equal single error probability parameter epsilon, which is sampled from a uniform distribution ranging from 0 to .50.","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"@model function model(data)\n    p ~ Dirichlet(fill(1, 4))\n    ϵ ~ Uniform(0, .5)\n    data ~ TrueErrorModel(; p, ϵ = fill(ϵ, 4))\nend","category":"page"},{"location":"parameter_estimation/#Estimate-the-Parameters","page":"Bayesian Parameter Estimation","title":"Estimate the Parameters","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Now that the Turing model has been specified, we can perform Bayesian parameter estimation with the function sample. We will use the No U-Turn Sampler (NUTS) to sample from the posterior distribution. The inputs into the sample function below are summarized as follows:","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"model(data): the Turing model with data passed\nNUTS(1000, .65): a sampler object for the No U-Turn Sampler for 1000 warmup samples.\nMCMCThreads(): instructs Turing to run each chain on a separate thread\nn_iterations: the number of iterations performed after warmup\nn_chains: the number of chains","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"# Estimate parameters\nchains = sample(model(data), NUTS(1000, .65), MCMCThreads(), 1000, 4)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"For ease of intepretation, we will convert the numerical indices of preference vector mathbfp to more informative labeled indices. ","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"name_map = Dict(\n    \"p[1]\" => \"pᵣᵣ\",\n    \"p[2]\" => \"pᵣₛ\",\n    \"p[3]\" => \"pₛᵣ\",\n    \"p[4]\" => \"pₛₛ\",\n)\nchains = replacenames(chains, name_map)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The output below shows the mean, standard deviation, effective sample size, and rhat for each of the five parameters. The pannel below shows the quantiles of the marginal distributions. ","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Chains MCMC chain (1000×20×4 Array{Float64, 3}):\n\nIterations        = 1001:1:2000\nNumber of chains  = 4\nSamples per chain = 1000\nWall duration     = 2.11 seconds\nCompute duration  = 6.21 seconds\nparameters        = pᵣᵣ, pᵣₛ, pₛᵣ, pₛₛ, ϵ\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ess_per_sec \n      Symbol   Float64   Float64   Float64     Float64     Float64   Float64       Float64 \n\n         pᵣᵣ    0.6580    0.0373    0.0005   6647.4436   3364.7026    1.0008      231.3522\n         pᵣₛ    0.1378    0.0293    0.0004   6554.7555   3621.5757    1.0000      228.1264\n         pₛᵣ    0.1180    0.0271    0.0004   5902.0436   2996.5486    1.0013      205.4099\n         pₛₛ    0.0862    0.0230    0.0003   6936.9475   3246.1778    1.0003      241.4279\n           ϵ    0.1018    0.0122    0.0002   6510.9497   3234.6554    1.0008      226.6018\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n\n         pᵣᵣ    0.5858    0.6331    0.6580    0.6833    0.7300\n         pᵣₛ    0.0843    0.1172    0.1365    0.1574    0.1980\n         pₛᵣ    0.0694    0.0991    0.1164    0.1362    0.1742\n         pₛₛ    0.0448    0.0699    0.0847    0.1012    0.1362\n           ϵ    0.0797    0.0937    0.1015    0.1095    0.1266","category":"page"},{"location":"parameter_estimation/#Evaluation","page":"Bayesian Parameter Estimation","title":"Evaluation","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"It is important to verify that the chains converged. We see that the chains converged according to hatr leq 105, and the trace plots below show that the chains look like \"hairy caterpillars\", which indicates the chains did not get stuck. ","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"post_plot = plot(chains, grid = false)\nvline!(post_plot, [missing .65 missing .15 missing .15 missing .05 missing .10], color = :black, linestyle = :dash)","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"(Image: )","category":"page"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The data-generating parameters are represented as black vertical lines in the density plots. As expected, the posterior distributions are centered near the data-generating parameters. Given that the data-generating and estimated model are the same, we would expect the posterior distributions to be near the data-generating parameters. ","category":"page"},{"location":"parameter_estimation/#References","page":"Bayesian Parameter Estimation","title":"References","text":"","category":"section"},{"location":"parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Birnbaum, M. H., & Quispe-Torreblanca, E. G. (2018). TEMAP2. R: True and error model analysis program in R. Judgment and Decision Making, 13(5), 428-440.","category":"page"},{"location":"bayes_factor/#Computing-the-Bayes-Factor","page":"Bayesian Model Comparison","title":"Computing the Bayes Factor","text":"","category":"section"},{"location":"bayes_factor/#Overview","page":"Bayesian Model Comparison","title":"Overview","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"In this tutorial, we will use the Bayes factor to compare the evidence for one model relative to another reference model. Computing the Bayes factor is challenging because it requires integrating the log likelihood over the model parameters. One method for approximating this complex integral is non-reversible parallel tempering (Bouchard-Côté et al., 2022) using  Pigeons.jl. ","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"In the tutorial below, we will compare two models which differ only in terms of assumptions about drift rate variability: the LBA and the RDM. The LBA assumes that the drift rate varies across trials and is otherwise deterministic, whereas the RDM assumes the drift rate varies within a trial as Gaussian noise, but not across trials. The difference between the models can be visualized with Plots.jl:","category":"page"},{"location":"bayes_factor/#Load-Packages","page":"Bayesian Model Comparison","title":"Load Packages","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Before proceeding, we will load the required packages.","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"using MCMCChains\nusing Pigeons\nusing Random\nusing TrueAndErrorModels\nusing Turing","category":"page"},{"location":"bayes_factor/#Data-Generating-Model","page":"Bayesian Model Comparison","title":"Data-Generating Model","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The next step is to generate simulated data for comparing the models. Here, we will assume that the LBA is the true data generating model:","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Random.seed!(258)\ndist = TrueErrorModel(; p = [0.65, .15, .15, .05], ϵ = fill(.10, 4))\ndata = rand(dist, 200)","category":"page"},{"location":"bayes_factor/#Define-Models","page":"Bayesian Model Comparison","title":"Define Models","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The following code blocks define the models along with their prior distributions using Turing.jl. Notice that the models are identical except for the log likelihood function.","category":"page"},{"location":"bayes_factor/#TE4-Model","page":"Bayesian Model Comparison","title":"TE4 Model","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"@model function te4_model(data)\n    p ~ Dirichlet(fill(1, 4))\n    ϵ ~ filldist(Uniform(0, .5), 4)\n    data ~ TrueErrorModel(p, ϵ)\nend","category":"page"},{"location":"bayes_factor/#TE1-Model","page":"Bayesian Model Comparison","title":"TE1 Model","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"@model function te1_model(data)\n    p ~ Dirichlet(fill(1, 4))\n    ϵ ~ Uniform(0, .5)\n    data ~ TrueErrorModel(p, fill(ϵ, 4))\nend","category":"page"},{"location":"bayes_factor/#Estimate-Marginal-Log-Likelihood","page":"Bayesian Model Comparison","title":"Estimate Marginal Log Likelihood","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The next step is to run the pigeons function to estimate the marginal log likelihood for each model. ","category":"page"},{"location":"bayes_factor/#TE4","page":"Bayesian Model Comparison","title":"TE4","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"pt_te4 = pigeons(target=TuringLogPotential(te4_model(data)), record=[traces])","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"────────────────────────────────────────────────────────────────────────────\n  scans        Λ      log(Z₁/Z₀)   min(α)     mean(α)    min(αₑ)   mean(αₑ) \n────────── ────────── ────────── ────────── ────────── ────────── ──────────\n        2       3.22      -47.6   0.000923      0.643          1          1 \n        4       1.86      -39.9      0.265      0.793          1          1 \n        8        3.6      -38.2      0.255        0.6          1          1 \n       16        3.2      -39.2      0.403      0.645          1          1 \n       32       3.51      -38.8       0.36       0.61          1          1 \n       64       3.56      -39.6      0.441      0.605          1          1 \n      128       3.78      -40.1      0.488       0.58          1          1 \n      256       3.63      -39.4      0.482      0.596          1          1 \n      512       3.61      -39.5      0.556      0.599          1          1 \n 1.02e+03       3.56      -39.2      0.577      0.604          1          1 \n────────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"name_map = Dict(\n    \"p[1]\" => \"pᵣᵣ\",\n    \"p[2]\" => \"pᵣₛ\",\n    \"p[3]\" => \"pₛᵣ\",\n    \"p[4]\" => \"pₛₛ\",\n    \"ϵ[1]\" => \"ϵᵣₛ₁\",\n    \"ϵ[2]\" => \"ϵᵣₛ₂\",\n    \"ϵ[3]\" => \"ϵₛᵣ₁\",\n    \"ϵ[4]\" => \"ϵₛᵣ₂\",\n)\nchain_te4 = Chains(pt_te4)\nchain_te4 = replacenames(chain_te4, name_map)","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Chains MCMC chain (1024×9×1 Array{Float64, 3}):\n\nIterations        = 1:1:1024\nNumber of chains  = 1\nSamples per chain = 1024\nparameters        = pᵣᵣ, pᵣₛ, pₛᵣ, pₛₛ, ϵᵣₛ₁, ϵᵣₛ₂, ϵₛᵣ₁, ϵₛᵣ₂\ninternals         = log_density\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   ess_per_sec \n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64       Missing \n\n         pᵣᵣ    0.5768    0.0824    0.0039   449.2267   570.8385    1.0027       missing\n         pᵣₛ    0.1820    0.0662    0.0033   391.3331   750.0271    1.0000       missing\n         pₛᵣ    0.1787    0.0579    0.0026   523.1174   740.9073    1.0002       missing\n         pₛₛ    0.0625    0.0297    0.0012   618.7097   755.8075    0.9995       missing\n        ϵᵣₛ₁    0.0517    0.0314    0.0014   529.0317   866.9172    0.9995       missing\n        ϵᵣₛ₂    0.0571    0.0342    0.0017   418.1905   657.3602    1.0010       missing\n        ϵₛᵣ₁    0.1995    0.1077    0.0048   514.3591   868.8844    1.0006       missing\n        ϵₛᵣ₂    0.2706    0.1235    0.0065   372.7194   763.7186    1.0005       missing\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n\n         pᵣᵣ    0.4293    0.5165    0.5762    0.6383    0.7335\n         pᵣₛ    0.0712    0.1317    0.1765    0.2275    0.3180\n         pₛᵣ    0.0820    0.1335    0.1760    0.2202    0.2987\n         pₛₛ    0.0179    0.0411    0.0576    0.0808    0.1294\n        ϵᵣₛ₁    0.0033    0.0245    0.0511    0.0754    0.1104\n        ϵᵣₛ₂    0.0033    0.0282    0.0566    0.0840    0.1238\n        ϵₛᵣ₁    0.0162    0.1078    0.2056    0.2830    0.3887\n        ϵₛᵣ₂    0.0232    0.1705    0.2894    0.3699    0.4639","category":"page"},{"location":"bayes_factor/#TE1","page":"Bayesian Model Comparison","title":"TE1","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"pt_te1 = pigeons(target=TuringLogPotential(te1_model(data)), record=[traces])","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"────────────────────────────────────────────────────────────────────────────\n  scans        Λ      log(Z₁/Z₀)   min(α)     mean(α)    min(αₑ)   mean(αₑ) \n────────── ────────── ────────── ────────── ────────── ────────── ──────────\n        2       3.18      -69.3   1.04e-16      0.647          1          1 \n        4       2.11      -41.9    0.00298      0.766          1          1 \n        8       3.41      -39.2      0.226      0.621          1          1 \n       16       2.96      -38.6      0.364      0.671          1          1 \n       32       3.71      -37.6      0.459      0.588          1          1 \n       64       3.55      -38.3      0.505      0.605          1          1 \n      128       3.42        -38      0.487       0.62          1          1 \n      256       3.48      -38.1      0.556      0.613          1          1 \n      512       3.28      -37.7      0.593      0.635          1          1 \n 1.02e+03       3.41        -38      0.578      0.621          1          1 \n────────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"name_map = Dict(\n    \"p[1]\" => \"pᵣᵣ\",\n    \"p[2]\" => \"pᵣₛ\",\n    \"p[3]\" => \"pₛᵣ\",\n    \"p[4]\" => \"pₛₛ\",\n)\nchain_te1 = Chains(pt_te1)\nchain_te1 = replacenames(chain_te1, name_map)","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Chains MCMC chain (1024×6×1 Array{Float64, 3}):\n\nIterations        = 1:1:1024\nNumber of chains  = 1\nSamples per chain = 1024\nparameters        = pᵣᵣ, pᵣₛ, pₛᵣ, pₛₛ, ϵ\ninternals         = log_density\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ess_per_sec \n      Symbol   Float64   Float64   Float64     Float64     Float64   Float64       Missing \n\n         pᵣᵣ    0.7077    0.0351    0.0011   1106.2442   1055.5828    1.0000       missing\n         pᵣₛ    0.1178    0.0261    0.0009    908.2753    965.3276    1.0009       missing\n         pₛᵣ    0.1408    0.0268    0.0008   1036.7903    867.0191    0.9992       missing\n         pₛₛ    0.0338    0.0140    0.0005    891.6153   1059.1575    1.0031       missing\n           ϵ    0.0874    0.0115    0.0004    952.5670    803.6060    0.9995       missing\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n\n         pᵣᵣ    0.6364    0.6843    0.7065    0.7329    0.7712\n         pᵣₛ    0.0717    0.0993    0.1165    0.1344    0.1746\n         pₛᵣ    0.0923    0.1213    0.1402    0.1589    0.1964\n         pₛₛ    0.0120    0.0235    0.0318    0.0422    0.0662\n           ϵ    0.0668    0.0795    0.0867    0.0947    0.1114","category":"page"},{"location":"bayes_factor/#Extract-marginal-log-likelihood","page":"Bayesian Model Comparison","title":"Extract marginal log likelihood","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"In the following code block, the function stepping_stone extracts that marginal log likelihood:","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"mll_te1 = stepping_stone(pt_te1)\nmll_te4 = stepping_stone(pt_te4)","category":"page"},{"location":"bayes_factor/#Compute-the-Bayes-Factor","page":"Bayesian Model Comparison","title":"Compute the Bayes Factor","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"The bayes factor is obtained by exponentiating the difference between marginal log likelihoods. The value of 1.21 indicates that the LBA is 1.21 times more likely to have generated the data. ","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"bf = exp(mll_te1 - mll_te4)","category":"page"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"3.3948019100884617","category":"page"},{"location":"bayes_factor/#References","page":"Bayesian Model Comparison","title":"References","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayesian Model Comparison","title":"Bayesian Model Comparison","text":"Syed, S., Bouchard-Côté, A., Deligiannidis, G., & Doucet, A. (2022). Non-reversible parallel tempering: a scalable highly parallel MCMC scheme. Journal of the Royal Statistical Society Series B: Statistical Methodology, 84(2), 321-350.","category":"page"},{"location":"overview/#Model-Overview","page":"Model Overview","title":"Model Overview","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"One challenge in evaluating theories of decision making is that data likely reflect a mixture of true preferences and response error. Suppose a person selects risky option mathcalR over safe option mathcalS. This response could arise through two different pathways. First, a person may truely prefer mathcalR to mathcalS and report his or her preferences accurately. Alternatively, this person may truely mathcalS, but select mathcalR by accident. True and Error Theory (TET; Birnbaum,  & Quispe-Torreblanca, 2018) provides a mathematical framework for distinguishing true preferences from errors in reporting due to various sources, such as trembling hand, failures of memory and/or reasoning, and lapses of attention. ","category":"page"},{"location":"overview/#Task","page":"Model Overview","title":"Task","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"TET can be applied to a wide variety of tasks in which subjects make repeated decisions from the same choice sets. As a simple example, we will consider a decision making task in which subjects choose between two sets of options: ","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"mathcalC_1 = mathcalR_1mathcalS_1","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"and ","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"mathcalC_2 = mathcalR_2mathcalS_2,","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"where mathcalR represents a risky gamble and mathcalS represents a safe gamble. In general, a generic gamble mathcalG is defined by the discrete payoff distribution:","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"mathcalG = (x_1 p_1 dots x_n p_n) ","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"where outcome x_i occurs with probability p_i. The key difference between gambles mathcalR and mathcalS is that mathrmVarmathcalR  mathrmVarmathcalS. An important requirement for TET is that subjects select an option from both choice sets at least twice within the same session. Assuming two replications each, the resulting joint response set contains 16 patterns: ","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"(mathcalR_1mathcalR_2mathcalR_1mathcalR_2)(mathcalR_1mathcalR_2mathcalR_1mathcalS_2) dots (mathcalS_1mathcalS_2mathcalS_1mathcalS_2).","category":"page"},{"location":"overview/#True-and-Error-Theory","page":"Model Overview","title":"True and Error Theory","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"As noted above, True and Error Theory provides a mathematical framework for distinguishing true preferences from errors in reporting errors due to various sources, such as trembling hand, failures of memory and/or reasoning, and lapses of attention. According to TET, there are four possible preference states, one for each possible option: RR, RS, SR, SS. For example, preference state SR indicates a person pefers the safe option in the first choice set, and the risky option in the second choice set.","category":"page"},{"location":"overview/#Parameters","page":"Model Overview","title":"Parameters","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"The full TET model contains 8 parameters in total. Four of the parameters represent the joint probability of the four true preference states:","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"p_mathrmRR: the probability of prefering the risky option in both choice sets\np_mathrmRS: the probability of prefering the risky option in the first choice set and prefering the safe option in the second choice set\np_mathrmSR: the probability of prefering the safe option in the first choice set and prefering the risky option in the second choice set\np_mathrmSS: the probability of prefering the safe option in both choice sets","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"subject to the constraint that p_mathrmRR + p_mathrmRS + p_mathrmSR + p_mathrmSS = 1.","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"The remaining four parameters correspond to error probabilities. ","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"epsilon_mathrmS_1: the error probability of selecting mathcalS_1 given that mathcalR_1 is prefered.\nepsilon_mathrmS_2: the error probability of selecting mathcalS_2 given that mathcalR_2 is prefered.\nepsilon_mathrmR_1: the error probability of selecting mathcalR_1 given that mathcalS_1 is prefered.\nepsilon_mathrmR_2: the error probability of selecting mathcalR_2 given that mathcalS_2 is prefered.","category":"page"},{"location":"overview/#Structure","page":"Model Overview","title":"Structure","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"The TET model is structured as a multinomial processing tree in which nodes correspond to cognitive states or processes, and branches correspond to transition probabilities. In total, the TET model has 16 equations, corresponding to the 16 possible response patterns. Each equation is displayed below. As an example, consider the first equation, which corresonds to response pattern (mathcalR_1mathcalR_2,mathcalR_1mathcalR_2). Although the risky option was selected for each decision, the TET model proposes that the response pattern could have been generated from any of the four preference states enumerated above. Each possible preference state occurs with a given probability and produces the observed choice pattern with a combination of correct and error responses. As an example, consider the first term in theta_1 in which the assumed preference state is RR:","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"p_mathrmRR cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2)","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"Under this assumption, each response is produced by correctly reporting the preference state. Hence, all four terms with epsilon_i use the complementary probability 1 - epsilon_i. Now consider the fourth term in which the assumed preference state is SS: ","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"p_mathrmSS cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"Under this alternative assumption, all four responses are produced through error. A similar line of reasoning is used to define the remaining equations below.","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{R}_2,\\mathcal{R}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalR_1mathcalR_2,mathcalR_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_1 =     p_mathrmRR cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmRS cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 +       p_mathrmSR cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmSS cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{R}_2,\\mathcal{R}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalR_1mathcalR_2,mathcalR_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_2 =     p_mathrmRR cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 +       p_mathrmRS cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) +       p_mathrmSR cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 +       p_mathrmSS cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{R}_2,\\mathcal{S}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalR_1mathcalR_2,mathcalS_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_3 =     p_mathrmRR cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmRS cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 +       p_mathrmSR cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmSS cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{R}_2,\\mathcal{S}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalR_1mathcalR_2,mathcalS_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_4 =     p_mathrmRR cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 +       p_mathrmRS cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) +       p_mathrmSR cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 +       p_mathrmSS cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{S}_2,\\mathcal{R}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalR_1mathcalS_2,mathcalR_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_5 =     p_mathrmRR cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmRS cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 +       p_mathrmSR cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmSS cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{S}_2,\\mathcal{R}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalR_1mathcalS_2,mathcalR_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_6 =     p_mathrmRR cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 +       p_mathrmRS cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) +       p_mathrmSR cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 +       p_mathrmSS cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{S}_2,\\mathcal{S}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalR_1mathcalS_2,mathcalS_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_7 =     p_mathrmRR cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmRS cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 +       p_mathrmSR cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmSS cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{R}_1\\mathcal{S}_2,\\mathcal{S}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalR_1mathcalS_2,mathcalS_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_8 =     p_mathrmRR cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 +       p_mathrmRS cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) +       p_mathrmSR cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 +       p_mathrmSS cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{R}_2,\\mathcal{R}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalS_1mathcalR_2,mathcalR_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_9 =     p_mathrmRR cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmRS cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 +       p_mathrmSR cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmSS cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{R}_2,\\mathcal{R}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalS_1mathcalR_2,mathcalR_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_10 =     p_mathrmRR cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 +       p_mathrmRS cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) +       p_mathrmSR cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 +       p_mathrmSS cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{R}_2,\\mathcal{S}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalS_1mathcalR_2,mathcalS_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_11 =     p_mathrmRR cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmRS cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 +       p_mathrmSR cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmSS cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{R}_2,\\mathcal{S}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalS_1mathcalR_2,mathcalS_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_12 =     p_mathrmRR cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 +       p_mathrmRS cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) +       p_mathrmSR cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 +       p_mathrmSS cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{S}_2,\\mathcal{R}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalS_1mathcalS_2,mathcalR_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_13 =     p_mathrmRR cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmRS cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmR_2 +       p_mathrmSR cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmSS cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmR_1 cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{S}_2,\\mathcal{R}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalS_1mathcalS_2,mathcalR_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_14 =     p_mathrmRR cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmS_1) cdot epsilon_mathrmS_2 +       p_mathrmRS cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmS_1) cdot (1 - epsilon_mathrmR_2) +       p_mathrmSR cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 cdot epsilon_mathrmR_1 cdot epsilon_mathrmS_2 +       p_mathrmSS cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmR_1 cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{S}_2,\\mathcal{S}_1\\mathcal{R}_2","page":"Model Overview","title":"mathcalS_1mathcalS_2,mathcalS_1mathcalR_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_15 =     p_mathrmRR cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmS_2) +       p_mathrmRS cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmS_1 cdot epsilon_mathrmR_2 +       p_mathrmSR cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmS_2) +       p_mathrmSS cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmR_2","category":"page"},{"location":"overview/#\\mathcal{S}_1\\mathcal{S}_2,\\mathcal{S}_1\\mathcal{S}_2","page":"Model Overview","title":"mathcalS_1mathcalS_2,mathcalS_1mathcalS_2","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"theta_16 =     p_mathrmRR cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 cdot epsilon_mathrmS_1 cdot epsilon_mathrmS_2 +       p_mathrmRS cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) cdot epsilon_mathrmS_1 cdot (1 - epsilon_mathrmR_2) +       p_mathrmSR cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 cdot (1 - epsilon_mathrmR_1) cdot epsilon_mathrmS_2 +       p_mathrmSS cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2) cdot (1 - epsilon_mathrmR_1) cdot (1 - epsilon_mathrmR_2)","category":"page"},{"location":"overview/#References","page":"Model Overview","title":"References","text":"","category":"section"},{"location":"overview/","page":"Model Overview","title":"Model Overview","text":"Birnbaum, M. H., & Quispe-Torreblanca, E. G. (2018). TEMAP2. R: True and error model analysis program in R. Judgment and Decision Making, 13(5), 428-440.","category":"page"},{"location":"#TrueAndErrorModels.jl","page":"Home","title":"TrueAndErrorModels.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The purpose of this package is to provide an implementation of True and Error Theory (TET; Birnbaum,  & Quispe-Torreblanca, 2018) in the Julia programming language. TET provides a mathematical framework for distinguishing between true preferences and errors in option evaluation and selection. For example, a person who selects risky option mathcalR over safe option mathcalS may have selected mathcalR because he or she truely prefers mathcalR, or may truely prefer mathcalS, but committed an error during the evaluation process. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"We demonstrate how to perform Bayesian parameter estimation and model comparison (e.g., Lee, 2018) using Turing.jl and Pigeons.jl. Use the navigation on the left to learn more about TET and how to perform Bayesian parameter estimation and model comparison.","category":"page"},{"location":"#References","page":"Home","title":"References","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Birnbaum, M. H., & Quispe-Torreblanca, E. G. (2018). TEMAP2. R: True and error model analysis program in R. Judgment and Decision Making, 13(5), 428-440.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Lee, M. D. (2018). Bayesian methods for analyzing true-and-error models. Judgment and Decision making, 13(6), 622-635.","category":"page"}]
}
