<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Bayesian Parameter Estimation · TrueAndErrorModels</title><meta name="title" content="Bayesian Parameter Estimation · TrueAndErrorModels"/><meta property="og:title" content="Bayesian Parameter Estimation · TrueAndErrorModels"/><meta property="twitter:title" content="Bayesian Parameter Estimation · TrueAndErrorModels"/><meta name="description" content="Documentation for TrueAndErrorModels."/><meta property="og:description" content="Documentation for TrueAndErrorModels."/><meta property="twitter:description" content="Documentation for TrueAndErrorModels."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">TrueAndErrorModels</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Bayesian Parameter Estimation</a><ul class="internal"><li><a class="tocitem" href="#Load-Packages"><span>Load Packages</span></a></li><li><a class="tocitem" href="#Generate-Data"><span>Generate Data</span></a></li><li><a class="tocitem" href="#Specify-Turing-Model"><span>Specify Turing Model</span></a></li><li><a class="tocitem" href="#Estimate-the-Parameters"><span>Estimate the Parameters</span></a></li><li><a class="tocitem" href="#Posterior-Summary"><span>Posterior Summary</span></a></li><li><a class="tocitem" href="#Evaluation"><span>Evaluation</span></a></li></ul></li><li><a class="tocitem" href="../bayes_factor/">Bayesian Model Comparison</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Bayesian Parameter Estimation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Bayesian Parameter Estimation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/itsdfish/TrueAndErrorModels.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/itsdfish/TrueAndErrorModels.jl/blob/main/docs/src/parameter_estimation.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="A-Simple-Turing-Model"><a class="docs-heading-anchor" href="#A-Simple-Turing-Model">A Simple Turing Model</a><a id="A-Simple-Turing-Model-1"></a><a class="docs-heading-anchor-permalink" href="#A-Simple-Turing-Model" title="Permalink"></a></h1><p>It is possible to use <a href="https://turinglang.org/stable/">Turing.jl</a> to perform Bayesian parameter estimation on models defined in SequentialSamplingModels.jl. Below, we show you how to estimate the parameters for the <a href="https://itsdfish.github.io/SequentialSamplingModels.jl/dev/lba/">Linear Ballistic Accumulator (LBA)</a> and to use it to estimate effects.</p><p>Note that you can easily swap the LBA model from this example for other <a href="https://itsdfish.github.io/SequentialSamplingModels.jl/dev/api/">SSM models</a> simply by changing the names of the parameters.</p><h2 id="Load-Packages"><a class="docs-heading-anchor" href="#Load-Packages">Load Packages</a><a id="Load-Packages-1"></a><a class="docs-heading-anchor-permalink" href="#Load-Packages" title="Permalink"></a></h2><p>The first step is to load the required packages. You will need to install each package in your local environment in order to run the code locally. We will also set a random number generator so that the results are reproducible.</p><pre><code class="language-julia hljs">using Turing
using TrueAndErrorModels
using Random
using StatsPlots
using Random

Random.seed!(25044)</code></pre><h2 id="Generate-Data"><a class="docs-heading-anchor" href="#Generate-Data">Generate Data</a><a id="Generate-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Generate-Data" title="Permalink"></a></h2><p>We will use the <a href="https://itsdfish.github.io/SequentialSamplingModels.jl/dev/lba/">LBA</a> distribution to simulate data (100 trials) with fixed parameters (those we want to recover only from the data using Bayesian modeling).</p><pre><code class="language-julia hljs"># Generate some data with known parameters
dist = TrueErrorModel(; p = [0.60, .30, .05, .05], ϵ = fill(.10, 4))
data = rand(dist, 200)</code></pre><pre><code class="language-julia hljs">16-element Vector{Int64}:
 80
 13
  8
  1
 16
 35
  ⋮
  8
  2
  3
  9
  1
  9</code></pre><p>The <code>rand()</code> function will sample random draws from the distribution, and store that into a named tuple of 2 vectors (one for <code>choice</code> and one for <code>rt</code>). The individual vectors can be accessed by their names using <code>data.choice</code> and <code>data.rt</code>.</p><h2 id="Specify-Turing-Model"><a class="docs-heading-anchor" href="#Specify-Turing-Model">Specify Turing Model</a><a id="Specify-Turing-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Specify-Turing-Model" title="Permalink"></a></h2><p>The code snippet below defines a model in Turing. The model function accepts a tuple containing a vector of choices and a vector of reaction times. The sampling statements define the prior distributions for each parameter. The non-decision time parameter <span>$\tau$</span> must be founded by the minimum reaction time, <code>min_rt</code>. The last sampling statement defines the likelihood of the data given the sampled parameter values.</p><pre><code class="language-julia hljs">@model function model(data)
    p ~ Dirichlet(fill(1, 4))
    ϵ ~ filldist(Uniform(0, .5), 4)
    data ~ TrueErrorModel(p, ϵ)
end</code></pre><h2 id="Estimate-the-Parameters"><a class="docs-heading-anchor" href="#Estimate-the-Parameters">Estimate the Parameters</a><a id="Estimate-the-Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Estimate-the-Parameters" title="Permalink"></a></h2><p>Finally, we perform parameter estimation with <code>sample()</code>, which takes the model, and details about the sampling algorithm:</p><ol><li><code>model(data)</code>: the Turing model with data passed</li><li><code>NUTS(1000, .65)</code>: a sampler object for the No U-Turn Sampler for 1000 warmup samples.</li><li><code>MCMCThreads()</code>: instructs Turing to run each chain on a separate thread</li><li><code>n_iterations</code>: the number of iterations performed after warmup</li><li><code>n_chains</code>: the number of chains</li></ol><pre><code class="language-julia hljs"># Estimate parameters
chains = sample(model(data), NUTS(1000, .65), MCMCThreads(), 1000, 4)</code></pre><pre><code class="language-julia hljs">Chains MCMC chain (1000×20×4 Array{Float64, 3}):

Iterations        = 1001:1:2000
Number of chains  = 4
Samples per chain = 1000
Wall duration     = 2.11 seconds
Compute duration  = 6.21 seconds
parameters        = p[1], p[2], p[3], p[4], ϵ[1], ϵ[2], ϵ[3], ϵ[4]
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ess_per_sec 
      Symbol   Float64   Float64   Float64     Float64     Float64   Float64       Float64 

        p[1]    0.5310    0.0844    0.0021   1611.5020   1931.9193    1.0008      259.5011
        p[2]    0.2536    0.0725    0.0017   1882.4309   2316.0608    1.0006      303.1290
        p[3]    0.1033    0.0512    0.0013   1520.5778   2258.6363    1.0006      244.8596
        p[4]    0.1121    0.0443    0.0010   1999.5107   2448.4595    1.0012      321.9824
        ϵ[1]    0.0654    0.0328    0.0008   1521.5648   1140.1998    1.0025      245.0185
        ϵ[2]    0.0984    0.0479    0.0011   1750.7039   1641.4243    1.0008      281.9169
        ϵ[3]    0.3015    0.1241    0.0030   1641.3979   1858.2680    1.0034      264.3153
        ϵ[4]    0.1382    0.0810    0.0019   1744.5089   1863.3155    1.0014      280.9193

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5% 
      Symbol   Float64   Float64   Float64   Float64   Float64 

        p[1]    0.3662    0.4706    0.5323    0.5931    0.6851
        p[2]    0.1378    0.1994    0.2444    0.2985    0.4119
        p[3]    0.0276    0.0635    0.0967    0.1349    0.2171
        p[4]    0.0427    0.0793    0.1064    0.1404    0.2091
        ϵ[1]    0.0060    0.0410    0.0655    0.0891    0.1292
        ϵ[2]    0.0087    0.0622    0.1018    0.1343    0.1841
        ϵ[3]    0.0438    0.2090    0.3166    0.4040    0.4880
        ϵ[4]    0.0116    0.0714    0.1318    0.1998    0.2997</code></pre><pre><code class="language-julia hljs">name_map = Dict(
    &quot;p[1]&quot; =&gt; &quot;pᵣᵣ&quot;,
    &quot;p[2]&quot; =&gt; &quot;pᵣₛ&quot;,
    &quot;p[3]&quot; =&gt; &quot;pₛᵣ&quot;,
    &quot;p[4]&quot; =&gt; &quot;pₛₛ&quot;,
    &quot;ϵ[1]&quot; =&gt; &quot;ϵᵣₛ₁&quot;,
    &quot;ϵ[2]&quot; =&gt; &quot;ϵᵣₛ₂&quot;,
    &quot;ϵ[3]&quot; =&gt; &quot;ϵₛᵣ₁&quot;,
    &quot;ϵ[4]&quot; =&gt; &quot;ϵₛᵣ₂&quot;,
)
chains = replacenames(chains, name_map)</code></pre><h2 id="Posterior-Summary"><a class="docs-heading-anchor" href="#Posterior-Summary">Posterior Summary</a><a id="Posterior-Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Posterior-Summary" title="Permalink"></a></h2><p>We can compute a description of the posterior distributions.</p><pre><code class="language-julia hljs"># Summarize posteriors
summarystats(chains)</code></pre><pre><code class="language-julia hljs">Summary Statistics
  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ess_per_sec 
      Symbol   Float64   Float64   Float64     Float64     Float64   Float64       Float64 

         pᵣᵣ    0.5310    0.0844    0.0021   1611.5020   1931.9193    1.0008      259.5011
         pᵣₛ    0.2536    0.0725    0.0017   1882.4309   2316.0608    1.0006      303.1290
         pₛᵣ    0.1033    0.0512    0.0013   1520.5778   2258.6363    1.0006      244.8596
         pₛₛ    0.1121    0.0443    0.0010   1999.5107   2448.4595    1.0012      321.9824
        ϵᵣₛ₁    0.0654    0.0328    0.0008   1521.5648   1140.1998    1.0025      245.0185
        ϵᵣₛ₂    0.0984    0.0479    0.0011   1750.7039   1641.4243    1.0008      281.9169
        ϵₛᵣ₁    0.3015    0.1241    0.0030   1641.3979   1858.2680    1.0034      264.3153
        ϵₛᵣ₂    0.1382    0.0810    0.0019   1744.5089   1863.3155    1.0014      280.9193</code></pre><p>As you can see, based on the mean values of the posterior distributions, the original parameters (<code>ν=[3.0, 2.0], A = .8, k = .2, τ = .3</code>) are successfully recovered from the data (the accuracy would increase with more data).</p><h2 id="Evaluation"><a class="docs-heading-anchor" href="#Evaluation">Evaluation</a><a id="Evaluation-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluation" title="Permalink"></a></h2><p>It is important to verify that the chains converged. We see that the chains converged according to <span>$\hat{r} \leq 1.05$</span>, and the trace plots below show that the chains look like &quot;hairy caterpillars&quot;, which indicates the chains did not get stuck. As expected, the posterior distributions are close to the data generating parameter values.</p><pre><code class="language-julia hljs">plot(chains)</code></pre><p><img src="../assets/posterior_distribution.png" alt/></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../bayes_factor/">Bayesian Model Comparison »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.6.0 on <span class="colophon-date" title="Monday 2 September 2024 21:45">Monday 2 September 2024</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
